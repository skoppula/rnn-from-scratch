(keras)skoppula@sls-sm-8:~/lstm-testing/rnn-from-scratch$ CUDA_VISIBLE_DEVICES=2 python lstm_all_variants.py -t -d shakespeare -v additive_sigmoid
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
{'dataset': 'shakespeare', 'train': True, 'variant': 'additive_sigmoid', 'generate': False, 'num_words': None}
('fetched data. trn/test data shape: ', (29743, 30), (29743, 30), (7436, 30), (7436, 30))
('num steps in trn and val epochs', 116, 29)
('Model name', 'lstm_all_variants')
building graph...
created model.
starting to train model!
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:81:00.0
Total memory: 11.90GiB
Free memory: 11.76GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:81:00.0)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3167 get requests, put_count=2840 evicted_count=1000 eviction_rate=0.352113 and unsatisfied allocation rate=0.450584
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4355 get requests, put_count=4238 evicted_count=1000 eviction_rate=0.23596 and unsatisfied allocation rate=0.261768
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 256 to 281
('epoch', 0, 'train_loss:', 4.3935676217079163, 'val_loss:', 1.0294062280654908)
('epoch', 1, 'train_loss:', 3.9696632647514343, 'val_loss:', 0.96039691209793088)
('epoch', 2, 'train_loss:', 3.7162319636344909, 'val_loss:', 0.89769903898239134)
('epoch', 3, 'train_loss:', 3.4688100099563597, 'val_loss:', 0.83911059141159061)
('epoch', 4, 'train_loss:', 3.2772902870178222, 'val_loss:', 0.8016418552398682)
('epoch', 5, 'train_loss:', 3.149360556602478, 'val_loss:', 0.77960521221160883)
('epoch', 6, 'train_loss:', 3.0673595929145812, 'val_loss:', 0.7610336232185364)
('epoch', 7, 'train_loss:', 3.0098631930351258, 'val_loss:', 0.7472853040695191)
('epoch', 8, 'train_loss:', 2.9590205526351929, 'val_loss:', 0.73507723331451413)
('epoch', 9, 'train_loss:', 2.9222247648239135, 'val_loss:', 0.72643867731094358)
('epoch', 10, 'train_loss:', 2.8842471599578858, 'val_loss:', 0.71868905305862429)
('epoch', 11, 'train_loss:', 2.8561580395698547, 'val_loss:', 0.71301775693893432)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1587114 get requests, put_count=1587146 evicted_count=3000 eviction_rate=0.00189019 and unsatisfied allocation rate=0.00190093
('epoch', 12, 'train_loss:', 2.8317300057411194, 'val_loss:', 0.70777407169342044)
('epoch', 13, 'train_loss:', 2.8165074920654298, 'val_loss:', 0.70375216007232666)
('epoch', 14, 'train_loss:', 2.8013252830505371, 'val_loss:', 0.69999228000640867)
('epoch', 15, 'train_loss:', 2.7834552621841429, 'val_loss:', 0.69622642278671265)
('epoch', 16, 'train_loss:', 2.7701114559173585, 'val_loss:', 0.69261942386627195)
('epoch', 17, 'train_loss:', 2.7613559770584106, 'val_loss:', 0.688020966053009)
('epoch', 18, 'train_loss:', 2.7475817918777468, 'val_loss:', 0.68772116422653196)
('epoch', 19, 'train_loss:', 2.7372388648986816, 'val_loss:', 0.68363622665405277)
('epoch', 20, 'train_loss:', 2.7275556421279905, 'val_loss:', 0.68108437776565556)
('epoch', 21, 'train_loss:', 2.7186194825172425, 'val_loss:', 0.67847854137420649)
('epoch', 22, 'train_loss:', 2.7067354822158816, 'val_loss:', 0.67799534797668459)
('epoch', 23, 'train_loss:', 2.6936640548706055, 'val_loss:', 0.67582942485809328)
('epoch', 24, 'train_loss:', 2.6888893938064573, 'val_loss:', 0.67204957962036138)
('epoch', 25, 'train_loss:', 2.6788385272026063, 'val_loss:', 0.6713894844055176)
('epoch', 26, 'train_loss:', 2.6728945994377136, 'val_loss:', 0.66731650352478022)
('epoch', 27, 'train_loss:', 2.6646375536918638, 'val_loss:', 0.66693745851516728)
('epoch', 28, 'train_loss:', 2.6570423364639284, 'val_loss:', 0.66528584957122805)
('epoch', 29, 'train_loss:', 2.648161118030548, 'val_loss:', 0.66188164710998532)
('epoch', 30, 'train_loss:', 2.6354060149192811, 'val_loss:', 0.65919340372085566)
('epoch', 31, 'train_loss:', 2.6318253159523008, 'val_loss:', 0.65664449214935305)
('epoch', 32, 'train_loss:', 2.6247055459022524, 'val_loss:', 0.65665850162506101)
('epoch', 33, 'train_loss:', 2.6150544691085815, 'val_loss:', 0.6537602734565735)
('epoch', 34, 'train_loss:', 2.6081422662734983, 'val_loss:', 0.6525346708297729)
('epoch', 35, 'train_loss:', 2.6001478433609009, 'val_loss:', 0.64832513093948363)
('epoch', 36, 'train_loss:', 2.5939045810699461, 'val_loss:', 0.64867486476898195)
('epoch', 37, 'train_loss:', 2.5864116048812864, 'val_loss:', 0.6459756302833557)
('epoch', 38, 'train_loss:', 2.5752463412284849, 'val_loss:', 0.64292270660400386)
('epoch', 39, 'train_loss:', 2.5719745945930481, 'val_loss:', 0.64359400033950809)
('epoch', 40, 'train_loss:', 2.5628191924095152, 'val_loss:', 0.64289507627487186)
('epoch', 41, 'train_loss:', 2.5598818731307982, 'val_loss:', 0.64019416570663457)
('epoch', 42, 'train_loss:', 2.5510910725593567, 'val_loss:', 0.63687431097030645)
('epoch', 43, 'train_loss:', 2.5448739242553713, 'val_loss:', 0.63651300907135011)
('epoch', 44, 'train_loss:', 2.5375554585456848, 'val_loss:', 0.63285825729370115)
('epoch', 45, 'train_loss:', 2.5316535782814027, 'val_loss:', 0.63103158473968501)
('epoch', 46, 'train_loss:', 2.5300889897346495, 'val_loss:', 0.63171670198440555)
('epoch', 47, 'train_loss:', 2.5183275842666628, 'val_loss:', 0.62928445100784303)
('epoch', 48, 'train_loss:', 2.5122550892829896, 'val_loss:', 0.63065676689147954)
('epoch', 49, 'train_loss:', 2.5067772507667541, 'val_loss:', 0.62707572460174565)
('epoch', 50, 'train_loss:', 2.4997852110862731, 'val_loss:', 0.62480546712875362)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 6742482 get requests, put_count=6742515 evicted_count=13000 eviction_rate=0.00192806 and unsatisfied allocation rate=0.00193045
('epoch', 51, 'train_loss:', 2.4918120098114014, 'val_loss:', 0.6260240125656128)
('epoch', 52, 'train_loss:', 2.4873180651664732, 'val_loss:', 0.6210807800292969)
('epoch', 53, 'train_loss:', 2.4812891125679015, 'val_loss:', 0.62010453939437871)
('epoch', 54, 'train_loss:', 2.4759966278076173, 'val_loss:', 0.61983755826950071)
('epoch', 55, 'train_loss:', 2.4694633865356446, 'val_loss:', 0.61644815444946288)
('epoch', 56, 'train_loss:', 2.4652607464790344, 'val_loss:', 0.6160546135902405)
('epoch', 57, 'train_loss:', 2.4609259796142577, 'val_loss:', 0.61365313529968257)
('epoch', 58, 'train_loss:', 2.4534058952331543, 'val_loss:', 0.61315616607666013)
('epoch', 59, 'train_loss:', 2.4477298498153686, 'val_loss:', 0.61413725376129147)
('epoch', 60, 'train_loss:', 2.4436833143234251, 'val_loss:', 0.61207189321517941)
('epoch', 61, 'train_loss:', 2.4398542356491091, 'val_loss:', 0.60918511152267452)
('epoch', 62, 'train_loss:', 2.4316329050064085, 'val_loss:', 0.60873682975769039)
('epoch', 63, 'train_loss:', 2.4257103395462036, 'val_loss:', 0.60792011976242066)
('epoch', 64, 'train_loss:', 2.4195798873901366, 'val_loss:', 0.60596313476562502)
('epoch', 65, 'train_loss:', 2.4167631697654723, 'val_loss:', 0.60451765537261959)
('epoch', 66, 'train_loss:', 2.4153357267379763, 'val_loss:', 0.60292418956756588)
('epoch', 67, 'train_loss:', 2.4057185721397398, 'val_loss:', 0.60235683679580687)
('epoch', 68, 'train_loss:', 2.4035654282569885, 'val_loss:', 0.60088994264602658)
('epoch', 69, 'train_loss:', 2.3972389221191408, 'val_loss:', 0.59972834110260009)
('epoch', 70, 'train_loss:', 2.3920549416542052, 'val_loss:', 0.5994238305091858)
('epoch', 71, 'train_loss:', 2.3883783864974975, 'val_loss:', 0.59617226600646978)
('epoch', 72, 'train_loss:', 2.3781879353523254, 'val_loss:', 0.59553648471832277)
('epoch', 73, 'train_loss:', 2.3771412658691404, 'val_loss:', 0.59428909301757815)
('epoch', 74, 'train_loss:', 2.3714320182800295, 'val_loss:', 0.59355646848678589)
('epoch', 75, 'train_loss:', 2.3676461052894591, 'val_loss:', 0.59055175662040715)
('epoch', 76, 'train_loss:', 2.3645050191879271, 'val_loss:', 0.5920481491088867)
('epoch', 77, 'train_loss:', 2.3578290510177613, 'val_loss:', 0.59008135318756105)
('epoch', 78, 'train_loss:', 2.3544528162479401, 'val_loss:', 0.58946781754493716)
('epoch', 79, 'train_loss:', 2.3448913872241972, 'val_loss:', 0.58702459216117864)
('epoch', 80, 'train_loss:', 2.3435572504997255, 'val_loss:', 0.58655692458152775)
('epoch', 81, 'train_loss:', 2.3370041894912719, 'val_loss:', 0.58484930515289302)
('epoch', 82, 'train_loss:', 2.3325787270069123, 'val_loss:', 0.58389565706253055)
('epoch', 83, 'train_loss:', 2.3341580712795258, 'val_loss:', 0.58269564628601078)
('epoch', 84, 'train_loss:', 2.3274972450733187, 'val_loss:', 0.58210038423538213)
('epoch', 85, 'train_loss:', 2.3215782284736632, 'val_loss:', 0.58214993715286256)
('epoch', 86, 'train_loss:', 2.3189384841918947, 'val_loss:', 0.57941718816757204)
('epoch', 87, 'train_loss:', 2.3131010735034945, 'val_loss:', 0.57994683980941775)
('epoch', 88, 'train_loss:', 2.3085801851749421, 'val_loss:', 0.57842708110809327)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 11776417 get requests, put_count=11776450 evicted_count=23000 eviction_rate=0.00195305 and unsatisfied allocation rate=0.00195441
('epoch', 89, 'train_loss:', 2.3039444065093995, 'val_loss:', 0.5767496252059936)
('epoch', 90, 'train_loss:', 2.301382658481598, 'val_loss:', 0.57516952514648434)
('epoch', 91, 'train_loss:', 2.2975249350070954, 'val_loss:', 0.57467088222503659)
('epoch', 92, 'train_loss:', 2.2902845740318298, 'val_loss:', 0.57301458120346072)
('epoch', 93, 'train_loss:', 2.2893090581893922, 'val_loss:', 0.573845192193985)
('epoch', 94, 'train_loss:', 2.2824135756492616, 'val_loss:', 0.5713545954227448)
('epoch', 95, 'train_loss:', 2.276231586933136, 'val_loss:', 0.57057661056518549)
('epoch', 96, 'train_loss:', 2.2743033266067503, 'val_loss:', 0.56984447240829472)
('epoch', 97, 'train_loss:', 2.2697990465164186, 'val_loss:', 0.56921940207481381)
('epoch', 98, 'train_loss:', 2.2660229659080504, 'val_loss:', 0.5689568734169006)
('epoch', 99, 'train_loss:', 2.2619644153118132, 'val_loss:', 0.56845421433448795)
('epoch', 100, 'train_loss:', 2.2570341014862061, 'val_loss:', 0.56766333937644964)
('epoch', 101, 'train_loss:', 2.2544834303855894, 'val_loss:', 0.56529679059982296)
('epoch', 102, 'train_loss:', 2.2513342130184175, 'val_loss:', 0.56437715291976931)
('epoch', 103, 'train_loss:', 2.2433308625221251, 'val_loss:', 0.56325285077095033)
('epoch', 104, 'train_loss:', 2.2446135115623473, 'val_loss:', 0.56142406344413753)
('epoch', 105, 'train_loss:', 2.2368655931949615, 'val_loss:', 0.56161797404289249)
('epoch', 106, 'train_loss:', 2.2381830084323884, 'val_loss:', 0.56138545513153071)
('epoch', 107, 'train_loss:', 2.2292986810207367, 'val_loss:', 0.5598698401451111)
('epoch', 108, 'train_loss:', 2.2240093564987182, 'val_loss:', 0.55953743219375607)
('epoch', 109, 'train_loss:', 2.2240221548080443, 'val_loss:', 0.55818257331848142)
('epoch', 110, 'train_loss:', 2.2203751647472383, 'val_loss:', 0.55795185804367065)
('epoch', 111, 'train_loss:', 2.2164343786239624, 'val_loss:', 0.55654023528099061)
('epoch', 112, 'train_loss:', 2.2102921128273012, 'val_loss:', 0.55568114399909974)
('epoch', 113, 'train_loss:', 2.2116301047801969, 'val_loss:', 0.55450707435607915)
('epoch', 114, 'train_loss:', 2.2038393700122834, 'val_loss:', 0.55365682363510127)
('epoch', 115, 'train_loss:', 2.2059768402576445, 'val_loss:', 0.55386952400207523)
('epoch', 116, 'train_loss:', 2.1975506711006165, 'val_loss:', 0.55166718482971189)
('epoch', 117, 'train_loss:', 2.1934180176258087, 'val_loss:', 0.55004439353942869)
('epoch', 118, 'train_loss:', 2.1901083409786226, 'val_loss:', 0.55055008411407469)
('epoch', 119, 'train_loss:', 2.1898350834846498, 'val_loss:', 0.55006746411323548)
('epoch', 120, 'train_loss:', 2.1870782446861265, 'val_loss:', 0.54762529850006103)
('epoch', 121, 'train_loss:', 2.1818866467475893, 'val_loss:', 0.54787438392639165)
('epoch', 122, 'train_loss:', 2.1784355294704438, 'val_loss:', 0.54603215456008913)
('epoch', 123, 'train_loss:', 2.1740691518783568, 'val_loss:', 0.54577734589576721)
('epoch', 124, 'train_loss:', 2.1719278037548064, 'val_loss:', 0.54476830244064334)
('epoch', 125, 'train_loss:', 2.1697158670425414, 'val_loss:', 0.54469763517379766)
('epoch', 126, 'train_loss:', 2.1641519260406494, 'val_loss:', 0.54325979113578793)
('epoch', 127, 'train_loss:', 2.1628299129009245, 'val_loss:', 0.54194908142089848)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 16858018 get requests, put_count=16858052 evicted_count=33000 eviction_rate=0.00195752 and unsatisfied allocation rate=0.00195842
('epoch', 128, 'train_loss:', 2.1604562175273894, 'val_loss:', 0.5416123247146607)
('epoch', 129, 'train_loss:', 2.1569858074188231, 'val_loss:', 0.5415955722332001)
('epoch', 130, 'train_loss:', 2.1485561919212341, 'val_loss:', 0.54050215601921081)
('epoch', 131, 'train_loss:', 2.1516446959972382, 'val_loss:', 0.53949505448341373)
('epoch', 132, 'train_loss:', 2.1453278672695162, 'val_loss:', 0.53907620191574102)
('epoch', 133, 'train_loss:', 2.1440045654773714, 'val_loss:', 0.53865605831146235)
('epoch', 134, 'train_loss:', 2.1407515656948091, 'val_loss:', 0.53737558960914611)
('epoch', 135, 'train_loss:', 2.1359423124790191, 'val_loss:', 0.53664044976234437)
('epoch', 136, 'train_loss:', 2.1347123408317565, 'val_loss:', 0.5376932299137116)
('epoch', 137, 'train_loss:', 2.1340546393394471, 'val_loss:', 0.53645664691925043)
('epoch', 138, 'train_loss:', 2.1280044484138489, 'val_loss:', 0.5350852656364441)
('epoch', 139, 'train_loss:', 2.12457026720047, 'val_loss:', 0.53397838830947875)
('epoch', 140, 'train_loss:', 2.1227788352966308, 'val_loss:', 0.53409302830696104)
('epoch', 141, 'train_loss:', 2.1188158488273618, 'val_loss:', 0.53131545186042783)
('epoch', 142, 'train_loss:', 2.1167673587799074, 'val_loss:', 0.53241758942604067)
('epoch', 143, 'train_loss:', 2.1158609998226168, 'val_loss:', 0.53322383165359499)
('epoch', 144, 'train_loss:', 2.1103084504604341, 'val_loss:', 0.52946925759315489)
('epoch', 145, 'train_loss:', 2.1066708981990816, 'val_loss:', 0.52919700741767883)
('epoch', 146, 'train_loss:', 2.1039699995517731, 'val_loss:', 0.52882666707038883)
('epoch', 147, 'train_loss:', 2.0991707527637482, 'val_loss:', 0.52950784921646121)
('epoch', 148, 'train_loss:', 2.0971872508525848, 'val_loss:', 0.52941514015197755)
('epoch', 149, 'train_loss:', 2.0967940759658812, 'val_loss:', 0.52825592756271367)
('epoch', 150, 'train_loss:', 2.0900488388538361, 'val_loss:', 0.5266678988933563)
('epoch', 151, 'train_loss:', 2.0917528212070464, 'val_loss:', 0.52680724740028384)
('epoch', 152, 'train_loss:', 2.0894341468811035, 'val_loss:', 0.52448897480964662)
('epoch', 153, 'train_loss:', 2.0837713074684143, 'val_loss:', 0.52409554243087764)
('epoch', 154, 'train_loss:', 2.0824882113933563, 'val_loss:', 0.52569366216659541)
('epoch', 155, 'train_loss:', 2.0799182176589968, 'val_loss:', 0.5233691263198853)
('epoch', 156, 'train_loss:', 2.077388460636139, 'val_loss:', 0.52340942025184634)
('epoch', 157, 'train_loss:', 2.072895802259445, 'val_loss:', 0.5222882461547852)
('epoch', 158, 'train_loss:', 2.0741856932640075, 'val_loss:', 0.52371554851531987)
('epoch', 159, 'train_loss:', 2.0681792044639589, 'val_loss:', 0.52193441987037659)
('epoch', 160, 'train_loss:', 2.0650170826911927, 'val_loss:', 0.52020885944366457)
('epoch', 161, 'train_loss:', 2.0608256959915163, 'val_loss:', 0.51885614395141599)
('epoch', 162, 'train_loss:', 2.059417713880539, 'val_loss:', 0.51838209390640255)
('epoch', 163, 'train_loss:', 2.0577214646339415, 'val_loss:', 0.51872942328453064)
('epoch', 164, 'train_loss:', 2.0577856910228731, 'val_loss:', 0.51901854157447813)
('epoch', 165, 'train_loss:', 2.0546578514575957, 'val_loss:', 0.5168339085578918)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 21965720 get requests, put_count=21965754 evicted_count=43000 eviction_rate=0.00195759 and unsatisfied allocation rate=0.00195828
('epoch', 166, 'train_loss:', 2.0531994342803954, 'val_loss:', 0.51804080128669738)
('epoch', 167, 'train_loss:', 2.0455663001537321, 'val_loss:', 0.51727863669395446)
('epoch', 168, 'train_loss:', 2.046539672613144, 'val_loss:', 0.51608767390251165)
('epoch', 169, 'train_loss:', 2.0437995266914366, 'val_loss:', 0.51661215662956239)
('epoch', 170, 'train_loss:', 2.0451309311389925, 'val_loss:', 0.51600832700729371)
('epoch', 171, 'train_loss:', 2.0394194805622101, 'val_loss:', 0.51367533445358271)
('epoch', 172, 'train_loss:', 2.0352325963974001, 'val_loss:', 0.51385275244712825)
('epoch', 173, 'train_loss:', 2.0332222461700438, 'val_loss:', 0.51284822583198553)
('epoch', 174, 'train_loss:', 2.0340759336948393, 'val_loss:', 0.50975423812866216)
('epoch', 175, 'train_loss:', 2.029757136106491, 'val_loss:', 0.51315757870674128)
('epoch', 176, 'train_loss:', 2.0264041209220887, 'val_loss:', 0.5085514867305756)
('epoch', 177, 'train_loss:', 2.0203174495697023, 'val_loss:', 0.51183409810066227)
('epoch', 178, 'train_loss:', 2.0278110003471372, 'val_loss:', 0.51190422654151913)
('epoch', 179, 'train_loss:', 2.0189616930484773, 'val_loss:', 0.50977336883544921)
('epoch', 180, 'train_loss:', 2.0157091510295868, 'val_loss:', 0.50927199363708497)
('epoch', 181, 'train_loss:', 2.0146797466278077, 'val_loss:', 0.50975120544433594)
('epoch', 182, 'train_loss:', 2.0143250524997711, 'val_loss:', 0.50798545598983769)
('epoch', 183, 'train_loss:', 2.0107505297660828, 'val_loss:', 0.50711996316909791)
('epoch', 184, 'train_loss:', 2.0080980551242829, 'val_loss:', 0.50814306616783145)
('epoch', 185, 'train_loss:', 2.0076306259632108, 'val_loss:', 0.50759918093681333)
('epoch', 186, 'train_loss:', 2.006271903514862, 'val_loss:', 0.50652701497077945)
('epoch', 187, 'train_loss:', 2.0058707308769228, 'val_loss:', 0.50591518640518185)
('epoch', 188, 'train_loss:', 2.0048627674579622, 'val_loss:', 0.50408022046089174)
('epoch', 189, 'train_loss:', 1.998168067932129, 'val_loss:', 0.50577973723411562)
('epoch', 190, 'train_loss:', 1.9956663167476654, 'val_loss:', 0.50174785614013673)
('epoch', 191, 'train_loss:', 1.9942072808742524, 'val_loss:', 0.50447051048278813)
('epoch', 192, 'train_loss:', 1.9916189205646515, 'val_loss:', 0.50452339529991153)
('epoch', 193, 'train_loss:', 1.9894238686561585, 'val_loss:', 0.5018849813938141)
('epoch', 194, 'train_loss:', 1.9881933987140656, 'val_loss:', 0.50222572445869451)
('epoch', 195, 'train_loss:', 1.987085520029068, 'val_loss:', 0.50093837022781373)
('epoch', 196, 'train_loss:', 1.9811092412471771, 'val_loss:', 0.50172088146209715)
('epoch', 197, 'train_loss:', 1.9837931346893312, 'val_loss:', 0.49934190154075625)
('epoch', 198, 'train_loss:', 1.9791767048835753, 'val_loss:', 0.50011551141738897)
('epoch', 199, 'train_loss:', 1.9772366952896119, 'val_loss:', 0.50117260694503785)
('epoch', 200, 'train_loss:', 1.977476577758789, 'val_loss:', 0.50123611569404602)
('epoch', 201, 'train_loss:', 1.9732189905643462, 'val_loss:', 0.49948219537734984)
('epoch', 202, 'train_loss:', 1.9733294939994812, 'val_loss:', 0.49798314571380614)
('epoch', 203, 'train_loss:', 1.9691744637489319, 'val_loss:', 0.49783241510391235)
('epoch', 204, 'train_loss:', 1.971762981414795, 'val_loss:', 0.49641528010368347)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 27111179 get requests, put_count=27111212 evicted_count=53000 eviction_rate=0.00195491 and unsatisfied allocation rate=0.0019555
('epoch', 205, 'train_loss:', 1.9666665613651275, 'val_loss:', 0.49601328969001768)
('epoch', 206, 'train_loss:', 1.961754423379898, 'val_loss:', 0.49712040305137634)
('epoch', 207, 'train_loss:', 1.9598242247104645, 'val_loss:', 0.49710719347000121)
('epoch', 208, 'train_loss:', 1.956402450799942, 'val_loss:', 0.49445194840431211)
('epoch', 209, 'train_loss:', 1.963191419839859, 'val_loss:', 0.49647752523422239)
('epoch', 210, 'train_loss:', 1.9504932045936585, 'val_loss:', 0.49414059400558474)
('epoch', 211, 'train_loss:', 1.9573888409137725, 'val_loss:', 0.49361003398895265)
('epoch', 212, 'train_loss:', 1.9510582482814789, 'val_loss:', 0.49373684287071229)
('epoch', 213, 'train_loss:', 1.9514448392391204, 'val_loss:', 0.49287832617759703)
('epoch', 214, 'train_loss:', 1.9492618262767791, 'val_loss:', 0.49390103578567507)
('epoch', 215, 'train_loss:', 1.9472418403625489, 'val_loss:', 0.49365665078163146)
('epoch', 216, 'train_loss:', 1.9485924625396729, 'val_loss:', 0.49127644658088682)
('epoch', 217, 'train_loss:', 1.9435589265823365, 'val_loss:', 0.49133973836898803)
('epoch', 218, 'train_loss:', 1.9427449774742127, 'val_loss:', 0.49078411698341368)
('epoch', 219, 'train_loss:', 1.94076566696167, 'val_loss:', 0.49197451591491698)
('epoch', 220, 'train_loss:', 1.9397263383865357, 'val_loss:', 0.48930876135826112)
('epoch', 221, 'train_loss:', 1.9357110714912416, 'val_loss:', 0.48958693623542787)
('epoch', 222, 'train_loss:', 1.9334658157825471, 'val_loss:', 0.48911248087882997)
('epoch', 223, 'train_loss:', 1.9358803415298462, 'val_loss:', 0.48934431314468385)
('epoch', 224, 'train_loss:', 1.930390751361847, 'val_loss:', 0.48934762477874755)
('epoch', 225, 'train_loss:', 1.9283692955970764, 'val_loss:', 0.49012550592422488)
('epoch', 226, 'train_loss:', 1.928637285232544, 'val_loss:', 0.48823150873184207)
('epoch', 227, 'train_loss:', 1.9251982712745666, 'val_loss:', 0.48598852753639221)
('epoch', 228, 'train_loss:', 1.9199495470523835, 'val_loss:', 0.48617579817771911)
('epoch', 229, 'train_loss:', 1.9185894691944123, 'val_loss:', 0.48887763738632201)
('epoch', 230, 'train_loss:', 1.9185092806816102, 'val_loss:', 0.48600103735923766)
('epoch', 231, 'train_loss:', 1.920190807580948, 'val_loss:', 0.48549312233924868)
('epoch', 232, 'train_loss:', 1.9151130294799805, 'val_loss:', 0.48664187431335448)
('epoch', 233, 'train_loss:', 1.9114747309684754, 'val_loss:', 0.48655742883682251)
('epoch', 234, 'train_loss:', 1.9154208219051361, 'val_loss:', 0.48443689107894899)
('epoch', 235, 'train_loss:', 1.9092990863323211, 'val_loss:', 0.48631388187408447)
('epoch', 236, 'train_loss:', 1.910291050672531, 'val_loss:', 0.4856811034679413)
('epoch', 237, 'train_loss:', 1.9067548096179963, 'val_loss:', 0.48360715985298158)
('epoch', 238, 'train_loss:', 1.9078147602081299, 'val_loss:', 0.48256170272827148)
('epoch', 239, 'train_loss:', 1.9068623077869415, 'val_loss:', 0.48453745484352112)
('epoch', 240, 'train_loss:', 1.9036064565181732, 'val_loss:', 0.48529100775718687)
('epoch', 241, 'train_loss:', 1.900484961271286, 'val_loss:', 0.48331225633621216)
('epoch', 242, 'train_loss:', 1.9009657931327819, 'val_loss:', 0.48222585201263429)
('epoch', 243, 'train_loss:', 1.8994082701206207, 'val_loss:', 0.48125736713409423)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 32233517 get requests, put_count=32233551 evicted_count=63000 eviction_rate=0.00195449 and unsatisfied allocation rate=0.00195495
('epoch', 244, 'train_loss:', 1.8969433426856994, 'val_loss:', 0.48129671454429629)
('epoch', 245, 'train_loss:', 1.896571422815323, 'val_loss:', 0.48029061198234557)
('epoch', 246, 'train_loss:', 1.8953746271133423, 'val_loss:', 0.48105599522590636)
('epoch', 247, 'train_loss:', 1.8933994305133819, 'val_loss:', 0.47927980184555052)
('epoch', 248, 'train_loss:', 1.8929145538806915, 'val_loss:', 0.4793049192428589)
('epoch', 249, 'train_loss:', 1.8900481259822846, 'val_loss:', 0.47951994419097899)
('epoch', 250, 'train_loss:', 1.8895054805278777, 'val_loss:', 0.47947597622871396)
('epoch', 251, 'train_loss:', 1.8900738227367402, 'val_loss:', 0.47991360187530518)
('epoch', 252, 'train_loss:', 1.8838000130653381, 'val_loss:', 0.48051151871681214)
('epoch', 253, 'train_loss:', 1.885859659910202, 'val_loss:', 0.47791375041007994)
('epoch', 254, 'train_loss:', 1.8828762686252594, 'val_loss:', 0.47771737933158875)
('epoch', 255, 'train_loss:', 1.8790509963035584, 'val_loss:', 0.47827927708625795)
('epoch', 256, 'train_loss:', 1.8810349714756012, 'val_loss:', 0.47781252026557924)
('epoch', 257, 'train_loss:', 1.8791274058818817, 'val_loss:', 0.47624197602272034)
('epoch', 258, 'train_loss:', 1.8787200725078583, 'val_loss:', 0.47691781997680666)
('epoch', 259, 'train_loss:', 1.8744119822978973, 'val_loss:', 0.47532207489013673)
('epoch', 260, 'train_loss:', 1.8737777185440063, 'val_loss:', 0.47578108549118042)
('epoch', 261, 'train_loss:', 1.871119099855423, 'val_loss:', 0.47667157173156738)
('epoch', 262, 'train_loss:', 1.8679005873203278, 'val_loss:', 0.47721515893936156)
('epoch', 263, 'train_loss:', 1.8723813617229461, 'val_loss:', 0.47447282910346983)
('epoch', 264, 'train_loss:', 1.8683400809764863, 'val_loss:', 0.47660593986511229)
('epoch', 265, 'train_loss:', 1.8670357906818389, 'val_loss:', 0.47410423398017881)
('epoch', 266, 'train_loss:', 1.8657168984413146, 'val_loss:', 0.47644996523857119)
('epoch', 267, 'train_loss:', 1.8631078803539276, 'val_loss:', 0.47281872391700747)
('epoch', 268, 'train_loss:', 1.8640743112564087, 'val_loss:', 0.47356455922126772)
('epoch', 269, 'train_loss:', 1.8612513184547423, 'val_loss:', 0.47453640580177309)
('epoch', 270, 'train_loss:', 1.8601443827152253, 'val_loss:', 0.47466067790985106)
('epoch', 271, 'train_loss:', 1.8591395652294158, 'val_loss:', 0.47394696354866028)
('epoch', 272, 'train_loss:', 1.8579576051235198, 'val_loss:', 0.47581154346466065)
('epoch', 273, 'train_loss:', 1.8523721992969513, 'val_loss:', 0.47285436749458315)
('epoch', 274, 'train_loss:', 1.85384143948555, 'val_loss:', 0.47410594940185546)
('epoch', 275, 'train_loss:', 1.8511962950229646, 'val_loss:', 0.47181042790412903)
('epoch', 276, 'train_loss:', 1.8525283014774323, 'val_loss:', 0.47092723608016968)
('epoch', 277, 'train_loss:', 1.8480347800254822, 'val_loss:', 0.47221662521362306)
('epoch', 278, 'train_loss:', 1.8498606669902802, 'val_loss:', 0.47044590711593626)
('epoch', 279, 'train_loss:', 1.8449911952018738, 'val_loss:', 0.47187042355537412)
('epoch', 280, 'train_loss:', 1.8469991087913513, 'val_loss:', 0.47137532472610472)
('epoch', 281, 'train_loss:', 1.8436495459079743, 'val_loss:', 0.46955281138420107)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 37337916 get requests, put_count=37337950 evicted_count=73000 eviction_rate=0.00195512 and unsatisfied allocation rate=0.00195552
('epoch', 282, 'train_loss:', 1.8425130414962769, 'val_loss:', 0.47033540964126586)
('epoch', 283, 'train_loss:', 1.8441382491588592, 'val_loss:', 0.47043351531028749)
('epoch', 284, 'train_loss:', 1.8412247872352601, 'val_loss:', 0.4713636565208435)
('epoch', 285, 'train_loss:', 1.841810358762741, 'val_loss:', 0.46868495702743529)
('epoch', 286, 'train_loss:', 1.8403972339630128, 'val_loss:', 0.46884027600288392)
('epoch', 287, 'train_loss:', 1.836412957906723, 'val_loss:', 0.46787708520889282)
('epoch', 288, 'train_loss:', 1.8358890581130982, 'val_loss:', 0.46972846508026123)
('epoch', 289, 'train_loss:', 1.8326308512687683, 'val_loss:', 0.4674827027320862)
('epoch', 290, 'train_loss:', 1.8325006568431854, 'val_loss:', 0.46818716406822203)
('epoch', 291, 'train_loss:', 1.8352639770507813, 'val_loss:', 0.46765721917152403)
('epoch', 292, 'train_loss:', 1.8335538351535796, 'val_loss:', 0.46712415099143983)
('epoch', 293, 'train_loss:', 1.8357100200653076, 'val_loss:', 0.46585073232650759)
('epoch', 294, 'train_loss:', 1.8329735291004181, 'val_loss:', 0.46689062237739565)
('epoch', 295, 'train_loss:', 1.827338638305664, 'val_loss:', 0.46570836663246157)
('epoch', 296, 'train_loss:', 1.8313248014450074, 'val_loss:', 0.46390669941902163)
('epoch', 297, 'train_loss:', 1.8269436621665955, 'val_loss:', 0.46669307231903079)
('epoch', 298, 'train_loss:', 1.8268320810794831, 'val_loss:', 0.46696992516517638)
('epoch', 299, 'train_loss:', 1.8235855424404144, 'val_loss:', 0.46635085105895996)
('epoch', 300, 'train_loss:', 1.8190742504596711, 'val_loss:', 0.46531916499137876)
('epoch', 301, 'train_loss:', 1.8246086108684541, 'val_loss:', 0.4642579412460327)
('epoch', 302, 'train_loss:', 1.8225346326828002, 'val_loss:', 0.46325058579444883)
('epoch', 303, 'train_loss:', 1.8177073979377747, 'val_loss:', 0.46361111640930175)
('epoch', 304, 'train_loss:', 1.818644015789032, 'val_loss:', 0.46367638587951659)
('epoch', 305, 'train_loss:', 1.8220677280426025, 'val_loss:', 0.46451230645179747)
('epoch', 306, 'train_loss:', 1.8148349082469941, 'val_loss:', 0.46438266515731813)
('epoch', 307, 'train_loss:', 1.8146485757827759, 'val_loss:', 0.46384431481361388)
('epoch', 308, 'train_loss:', 1.8152477979660033, 'val_loss:', 0.46433486938476565)
('epoch', 309, 'train_loss:', 1.8136085700988769, 'val_loss:', 0.46151013135910035)
('epoch', 310, 'train_loss:', 1.8083230113983155, 'val_loss:', 0.46175453543663025)
('epoch', 311, 'train_loss:', 1.8099707663059235, 'val_loss:', 0.46101035833358767)
('epoch', 312, 'train_loss:', 1.8115764474868774, 'val_loss:', 0.46325913071632385)
('epoch', 313, 'train_loss:', 1.8116886770725251, 'val_loss:', 0.46293426394462583)
('epoch', 314, 'train_loss:', 1.8097640132904054, 'val_loss:', 0.46067791581153872)
('epoch', 315, 'train_loss:', 1.805368685722351, 'val_loss:', 0.46140946030616758)
('epoch', 316, 'train_loss:', 1.8044655168056487, 'val_loss:', 0.46102687239646911)
('epoch', 317, 'train_loss:', 1.8062242984771728, 'val_loss:', 0.46322950720787048)
('epoch', 318, 'train_loss:', 1.805022429227829, 'val_loss:', 0.46176788926124573)
('epoch', 319, 'train_loss:', 1.8045574665069579, 'val_loss:', 0.46083921670913697)
('epoch', 320, 'train_loss:', 1.8033475959300995, 'val_loss:', 0.45937389612197876)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 42443739 get requests, put_count=42443772 evicted_count=83000 eviction_rate=0.00195553 and unsatisfied allocation rate=0.00195591
('epoch', 321, 'train_loss:', 1.7996418571472168, 'val_loss:', 0.46042819380760192)
('epoch', 322, 'train_loss:', 1.7977359521389007, 'val_loss:', 0.46161636471748352)
('epoch', 323, 'train_loss:', 1.7970904076099397, 'val_loss:', 0.46011498451232913)
('epoch', 324, 'train_loss:', 1.7952617847919463, 'val_loss:', 0.45861477375030518)
('epoch', 325, 'train_loss:', 1.7962141990661622, 'val_loss:', 0.46029797554016111)
('epoch', 326, 'train_loss:', 1.7951637506484985, 'val_loss:', 0.46102325201034544)
('epoch', 327, 'train_loss:', 1.7979020524024962, 'val_loss:', 0.45856717944145203)
('epoch', 328, 'train_loss:', 1.7930310714244841, 'val_loss:', 0.45903411030769348)
('epoch', 329, 'train_loss:', 1.7917003083229064, 'val_loss:', 0.45901563167572024)
('epoch', 330, 'train_loss:', 1.7882503306865691, 'val_loss:', 0.45922827243804931)
('epoch', 331, 'train_loss:', 1.7895241522789, 'val_loss:', 0.45968798279762269)
('epoch', 332, 'train_loss:', 1.790779402256012, 'val_loss:', 0.45549375295639039)
('epoch', 333, 'train_loss:', 1.786855584383011, 'val_loss:', 0.4580285561084747)
('epoch', 334, 'train_loss:', 1.7873962426185608, 'val_loss:', 0.45879880547523499)
('epoch', 335, 'train_loss:', 1.787900711297989, 'val_loss:', 0.45616336703300475)
('epoch', 336, 'train_loss:', 1.7820377409458161, 'val_loss:', 0.45728516340255737)
('epoch', 337, 'train_loss:', 1.7832846248149872, 'val_loss:', 0.45700469374656677)
('epoch', 338, 'train_loss:', 1.7836789143085481, 'val_loss:', 0.45645818114280701)
('epoch', 339, 'train_loss:', 1.7814607191085816, 'val_loss:', 0.4574203073978424)
('epoch', 340, 'train_loss:', 1.7801334536075593, 'val_loss:', 0.45714861392974854)
('epoch', 341, 'train_loss:', 1.7825456583499908, 'val_loss:', 0.45503347635269165)
('epoch', 342, 'train_loss:', 1.7789747607707977, 'val_loss:', 0.45738853812217711)
('epoch', 343, 'train_loss:', 1.7786362206935882, 'val_loss:', 0.4558607268333435)
('epoch', 344, 'train_loss:', 1.7795427191257476, 'val_loss:', 0.45529956579208375)
('epoch', 345, 'train_loss:', 1.7766471004486084, 'val_loss:', 0.45625846385955809)
('epoch', 346, 'train_loss:', 1.7763727331161498, 'val_loss:', 0.4543245220184326)
('epoch', 347, 'train_loss:', 1.7758904719352722, 'val_loss:', 0.45524715542793276)
('epoch', 348, 'train_loss:', 1.7749667143821717, 'val_loss:', 0.45552935719490051)
('epoch', 349, 'train_loss:', 1.7714748477935791, 'val_loss:', 0.45537935495376586)
('epoch', 350, 'train_loss:', 1.7711405301094054, 'val_loss:', 0.45567087292671205)
('epoch', 351, 'train_loss:', 1.7724376153945922, 'val_loss:', 0.45160844445228576)
('epoch', 352, 'train_loss:', 1.7711981904506684, 'val_loss:', 0.45486111402511598)
('epoch', 353, 'train_loss:', 1.7728712093830108, 'val_loss:', 0.45322490930557252)
('epoch', 354, 'train_loss:', 1.7746937763690949, 'val_loss:', 0.45517521023750307)
('epoch', 355, 'train_loss:', 1.7706372952461242, 'val_loss:', 0.45284337401390073)
('epoch', 356, 'train_loss:', 1.7681505036354066, 'val_loss:', 0.45241254687309262)
('epoch', 357, 'train_loss:', 1.7674198710918427, 'val_loss:', 0.45308723330497741)
('epoch', 358, 'train_loss:', 1.7693261420726776, 'val_loss:', 0.45390908837318422)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 47542633 get requests, put_count=47542667 evicted_count=93000 eviction_rate=0.00195614 and unsatisfied allocation rate=0.00195645
('epoch', 359, 'train_loss:', 1.7635972428321838, 'val_loss:', 0.45261218428611755)
('epoch', 360, 'train_loss:', 1.7645421350002288, 'val_loss:', 0.45227151036262514)
('epoch', 361, 'train_loss:', 1.7626172387599945, 'val_loss:', 0.45260356545448305)
('epoch', 362, 'train_loss:', 1.760340324640274, 'val_loss:', 0.45315503716468813)
('epoch', 363, 'train_loss:', 1.7631892251968384, 'val_loss:', 0.45146146655082703)
('epoch', 364, 'train_loss:', 1.7579770720005035, 'val_loss:', 0.45476884841918946)
('epoch', 365, 'train_loss:', 1.7573124396800994, 'val_loss:', 0.45440761804580687)
('epoch', 366, 'train_loss:', 1.758521912097931, 'val_loss:', 0.45249028921127321)
('epoch', 367, 'train_loss:', 1.7567108440399171, 'val_loss:', 0.45176086425781248)
('epoch', 368, 'train_loss:', 1.7551703155040741, 'val_loss:', 0.45041753649711608)
('epoch', 369, 'train_loss:', 1.756037791967392, 'val_loss:', 0.45069907426834105)
('epoch', 370, 'train_loss:', 1.7539005124568938, 'val_loss:', 0.45217847347259521)
('epoch', 371, 'train_loss:', 1.752505865097046, 'val_loss:', 0.45126172184944152)
('epoch', 372, 'train_loss:', 1.7530450117588043, 'val_loss:', 0.4489293956756592)
('epoch', 373, 'train_loss:', 1.7531227016448974, 'val_loss:', 0.45091042995452879)
('epoch', 374, 'train_loss:', 1.7528309035301208, 'val_loss:', 0.45032168865203859)
('epoch', 375, 'train_loss:', 1.7491339612007142, 'val_loss:', 0.44981739997863768)
('epoch', 376, 'train_loss:', 1.7496568095684051, 'val_loss:', 0.45014945149421692)
('epoch', 377, 'train_loss:', 1.7476276099681853, 'val_loss:', 0.44981966376304627)
('epoch', 378, 'train_loss:', 1.747864465713501, 'val_loss:', 0.44938586235046385)
('epoch', 379, 'train_loss:', 1.7470233631134033, 'val_loss:', 0.45035808205604555)
('epoch', 380, 'train_loss:', 1.7467848873138427, 'val_loss:', 0.4494706666469574)
('epoch', 381, 'train_loss:', 1.7469968533515929, 'val_loss:', 0.45022016048431396)
('epoch', 382, 'train_loss:', 1.7447656655311585, 'val_loss:', 0.44821176528930662)
('epoch', 383, 'train_loss:', 1.7476595544815063, 'val_loss:', 0.44956254482269287)
('epoch', 384, 'train_loss:', 1.7426138567924498, 'val_loss:', 0.44849169015884399)
('epoch', 385, 'train_loss:', 1.7452615952491761, 'val_loss:', 0.44985146045684815)
('epoch', 386, 'train_loss:', 1.74315544962883, 'val_loss:', 0.45154529571533203)
('epoch', 387, 'train_loss:', 1.7439780914783478, 'val_loss:', 0.44926294565200808)
('epoch', 388, 'train_loss:', 1.740822674036026, 'val_loss:', 0.44947274327278136)
('epoch', 389, 'train_loss:', 1.737906483411789, 'val_loss:', 0.44953221201896665)
('epoch', 390, 'train_loss:', 1.7388867771625518, 'val_loss:', 0.44585531830787661)
('epoch', 391, 'train_loss:', 1.736331559419632, 'val_loss:', 0.44772298574447633)
('epoch', 392, 'train_loss:', 1.7414904129505158, 'val_loss:', 0.45022952795028687)
('epoch', 393, 'train_loss:', 1.7362359547615052, 'val_loss:', 0.44694321036338808)
('epoch', 394, 'train_loss:', 1.7333005475997925, 'val_loss:', 0.44720840096473696)
('epoch', 395, 'train_loss:', 1.7361326682567597, 'val_loss:', 0.4463894832134247)
('epoch', 396, 'train_loss:', 1.7348400330543519, 'val_loss:', 0.44592353820800779)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 52595285 get requests, put_count=52595318 evicted_count=103000 eviction_rate=0.00195835 and unsatisfied allocation rate=0.00195865
('epoch', 397, 'train_loss:', 1.7323262393474579, 'val_loss:', 0.44657525897026062)
('epoch', 398, 'train_loss:', 1.7346184396743773, 'val_loss:', 0.44705634713172915)
('epoch', 399, 'train_loss:', 1.7332206928730012, 'val_loss:', 0.44562486052513123)
('epoch', 400, 'train_loss:', 1.7335084629058839, 'val_loss:', 0.44496872782707214)
('epoch', 401, 'train_loss:', 1.7302207660675049, 'val_loss:', 0.44731684565544128)
('epoch', 402, 'train_loss:', 1.7301607286930085, 'val_loss:', 0.44697936773300173)
('epoch', 403, 'train_loss:', 1.7290791654586792, 'val_loss:', 0.4454761230945587)
('epoch', 404, 'train_loss:', 1.7308970344066621, 'val_loss:', 0.44751020073890685)
('epoch', 405, 'train_loss:', 1.727743763923645, 'val_loss:', 0.44569554209709167)
('epoch', 406, 'train_loss:', 1.7285763752460479, 'val_loss:', 0.44497844099998474)
('epoch', 407, 'train_loss:', 1.7240057623386382, 'val_loss:', 0.4477458941936493)
('epoch', 408, 'train_loss:', 1.7219034206867219, 'val_loss:', 0.44603622555732725)
('epoch', 409, 'train_loss:', 1.7256649780273436, 'val_loss:', 0.44458963394165041)
('epoch', 410, 'train_loss:', 1.7216905796527862, 'val_loss:', 0.44490934371948243)
('epoch', 411, 'train_loss:', 1.7251314961910247, 'val_loss:', 0.44525159597396852)
('epoch', 412, 'train_loss:', 1.7228074228763581, 'val_loss:', 0.44362370371818544)
('epoch', 413, 'train_loss:', 1.723827028274536, 'val_loss:', 0.44533157706260679)
('epoch', 414, 'train_loss:', 1.7198280203342438, 'val_loss:', 0.44470024943351744)
('epoch', 415, 'train_loss:', 1.7219923472404479, 'val_loss:', 0.44444819927215579)
('epoch', 416, 'train_loss:', 1.7229893004894257, 'val_loss:', 0.44387692332267759)
('epoch', 417, 'train_loss:', 1.7182711434364319, 'val_loss:', 0.44421346068382261)
('epoch', 418, 'train_loss:', 1.7217800951004028, 'val_loss:', 0.44417664885520936)
('epoch', 419, 'train_loss:', 1.7185169875621795, 'val_loss:', 0.44302019476890564)
('epoch', 420, 'train_loss:', 1.7180372416973113, 'val_loss:', 0.44628579616546632)
('epoch', 421, 'train_loss:', 1.7160971701145171, 'val_loss:', 0.44593583583831786)
('epoch', 422, 'train_loss:', 1.7203930366039275, 'val_loss:', 0.44243255853652952)
('epoch', 423, 'train_loss:', 1.7156054151058198, 'val_loss:', 0.44214465260505675)
('epoch', 424, 'train_loss:', 1.7165448439121247, 'val_loss:', 0.44261106014251711)
('epoch', 425, 'train_loss:', 1.7170462393760682, 'val_loss:', 0.44349772691726685)
('epoch', 426, 'train_loss:', 1.7125285804271697, 'val_loss:', 0.44356049776077272)
('epoch', 427, 'train_loss:', 1.7135236382484436, 'val_loss:', 0.44167810201644897)
('epoch', 428, 'train_loss:', 1.7099585986137391, 'val_loss:', 0.44401578068733216)
('epoch', 429, 'train_loss:', 1.7151284122467041, 'val_loss:', 0.44269837379455568)
('epoch', 430, 'train_loss:', 1.7121515405178069, 'val_loss:', 0.44356495976448057)
('epoch', 431, 'train_loss:', 1.7071051943302153, 'val_loss:', 0.44242290854454042)
('epoch', 432, 'train_loss:', 1.7083435785770416, 'val_loss:', 0.44099652171134951)
('epoch', 433, 'train_loss:', 1.707808586359024, 'val_loss:', 0.44341317653656004)
('epoch', 434, 'train_loss:', 1.7104141330718994, 'val_loss:', 0.44344018459320067)
('epoch', 435, 'train_loss:', 1.7088390493392944, 'val_loss:', 0.44215010046958925)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 57700007 get requests, put_count=57700040 evicted_count=113000 eviction_rate=0.0019584 and unsatisfied allocation rate=0.00195868
('epoch', 436, 'train_loss:', 1.7048097681999206, 'val_loss:', 0.4423444962501526)
('epoch', 437, 'train_loss:', 1.7042291903495788, 'val_loss:', 0.44056368112564087)
('epoch', 438, 'train_loss:', 1.7018670499324799, 'val_loss:', 0.44215364813804625)
('epoch', 439, 'train_loss:', 1.7073067331314087, 'val_loss:', 0.44144246697425843)
('epoch', 440, 'train_loss:', 1.7027991795539856, 'val_loss:', 0.43897942543029783)
('epoch', 441, 'train_loss:', 1.7022605836391449, 'val_loss:', 0.4421383202075958)
('epoch', 442, 'train_loss:', 1.70371138215065, 'val_loss:', 0.44147153973579406)
('epoch', 443, 'train_loss:', 1.7010591077804564, 'val_loss:', 0.44162961602210998)
('epoch', 444, 'train_loss:', 1.7013076233863831, 'val_loss:', 0.44094925165176391)
('epoch', 445, 'train_loss:', 1.7003164660930634, 'val_loss:', 0.44075494766235351)
('epoch', 446, 'train_loss:', 1.7014079856872559, 'val_loss:', 0.44164130568504334)
('epoch', 447, 'train_loss:', 1.6998487758636474, 'val_loss:', 0.43989466547966005)
('epoch', 448, 'train_loss:', 1.6949789607524872, 'val_loss:', 0.44149925947189333)
('epoch', 449, 'train_loss:', 1.7007506012916564, 'val_loss:', 0.4409773910045624)
('epoch', 450, 'train_loss:', 1.6956494343280792, 'val_loss:', 0.44033713102340699)
('epoch', 451, 'train_loss:', 1.6992991447448731, 'val_loss:', 0.44031670451164245)
('epoch', 452, 'train_loss:', 1.6970222556591035, 'val_loss:', 0.44049584031105044)
('epoch', 453, 'train_loss:', 1.6925132703781127, 'val_loss:', 0.43826923489570618)
('epoch', 454, 'train_loss:', 1.6954556024074554, 'val_loss:', 0.4385094082355499)
('epoch', 455, 'train_loss:', 1.6960729157924652, 'val_loss:', 0.43983720302581786)
('epoch', 456, 'train_loss:', 1.6974253785610198, 'val_loss:', 0.43862255811691286)
('epoch', 457, 'train_loss:', 1.6963066685199737, 'val_loss:', 0.44040872931480407)
('epoch', 458, 'train_loss:', 1.6955058765411377, 'val_loss:', 0.44032364726066592)
('epoch', 459, 'train_loss:', 1.6929599416255952, 'val_loss:', 0.43969357132911679)
('epoch', 460, 'train_loss:', 1.6915656590461732, 'val_loss:', 0.44123439908027651)
('epoch', 461, 'train_loss:', 1.6931092059612274, 'val_loss:', 0.44030979990959168)
('epoch', 462, 'train_loss:', 1.6940979158878327, 'val_loss:', 0.44020139336586001)
('epoch', 463, 'train_loss:', 1.6919377648830414, 'val_loss:', 0.43712183713912967)
('epoch', 464, 'train_loss:', 1.691929042339325, 'val_loss:', 0.43743598699569702)
('epoch', 465, 'train_loss:', 1.6879012382030487, 'val_loss:', 0.43939552545547483)
('epoch', 466, 'train_loss:', 1.6890373349189758, 'val_loss:', 0.43957586407661436)
('epoch', 467, 'train_loss:', 1.6885633611679076, 'val_loss:', 0.43866339683532712)
('epoch', 468, 'train_loss:', 1.685998957157135, 'val_loss:', 0.43949445843696594)
('epoch', 469, 'train_loss:', 1.6875142884254455, 'val_loss:', 0.43817870140075682)
('epoch', 470, 'train_loss:', 1.6886730480194092, 'val_loss:', 0.43656353473663329)
('epoch', 471, 'train_loss:', 1.6851100885868073, 'val_loss:', 0.43972229123115542)
('epoch', 472, 'train_loss:', 1.6800339210033417, 'val_loss:', 0.43690932989120485)
('epoch', 473, 'train_loss:', 1.6837313592433929, 'val_loss:', 0.43737138748168947)
('epoch', 474, 'train_loss:', 1.6863402783870698, 'val_loss:', 0.43851546645164491)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 62871890 get requests, put_count=62871923 evicted_count=123000 eviction_rate=0.00195636 and unsatisfied allocation rate=0.00195661
('epoch', 475, 'train_loss:', 1.6826639676094055, 'val_loss:', 0.43835095047950745)
('epoch', 476, 'train_loss:', 1.6855523765087128, 'val_loss:', 0.43863811492919924)
('epoch', 477, 'train_loss:', 1.6808022928237916, 'val_loss:', 0.43763550400733947)
('epoch', 478, 'train_loss:', 1.6824031937122346, 'val_loss:', 0.43809418559074403)
('epoch', 479, 'train_loss:', 1.6797981202602386, 'val_loss:', 0.43802440047264102)
('epoch', 480, 'train_loss:', 1.6785991823673247, 'val_loss:', 0.43862448573112489)
('epoch', 481, 'train_loss:', 1.6805906164646149, 'val_loss:', 0.43740972638130188)
('epoch', 482, 'train_loss:', 1.6812721276283265, 'val_loss:', 0.43739325642585752)
('epoch', 483, 'train_loss:', 1.6793708682060242, 'val_loss:', 0.43763507843017579)
('epoch', 484, 'train_loss:', 1.6781691002845764, 'val_loss:', 0.43762731313705444)
('epoch', 485, 'train_loss:', 1.6741454660892487, 'val_loss:', 0.43627673625946045)
('epoch', 486, 'train_loss:', 1.6796562325954438, 'val_loss:', 0.43444584131240843)
('epoch', 487, 'train_loss:', 1.6757545065879822, 'val_loss:', 0.4365663206577301)
('epoch', 488, 'train_loss:', 1.6778196799755096, 'val_loss:', 0.43628992915153503)
('epoch', 489, 'train_loss:', 1.6767718958854676, 'val_loss:', 0.4371943974494934)
('epoch', 490, 'train_loss:', 1.6761698698997498, 'val_loss:', 0.43736706137657166)
('epoch', 491, 'train_loss:', 1.676111831665039, 'val_loss:', 0.43666351914405821)
('epoch', 492, 'train_loss:', 1.6753091204166413, 'val_loss:', 0.43523750543594358)
('epoch', 493, 'train_loss:', 1.6734774732589721, 'val_loss:', 0.43558573365211489)
('epoch', 494, 'train_loss:', 1.6753226125240326, 'val_loss:', 0.43564820051193237)
('epoch', 495, 'train_loss:', 1.6747792756557465, 'val_loss:', 0.43607067584991455)
('epoch', 496, 'train_loss:', 1.6724108064174652, 'val_loss:', 0.43545818090438843)
('epoch', 497, 'train_loss:', 1.6678713726997376, 'val_loss:', 0.43574064016342162)
('epoch', 498, 'train_loss:', 1.6677932715415955, 'val_loss:', 0.43447824358940124)
('epoch', 499, 'train_loss:', 1.6737398529052734, 'val_loss:', 0.4346871364116669)
('epoch', 500, 'train_loss:', 1.6709807217121124, 'val_loss:', 0.435589519739151)
('epoch', 501, 'train_loss:', 1.6688830602169036, 'val_loss:', 0.43562645435333253)
('epoch', 502, 'train_loss:', 1.6677468502521515, 'val_loss:', 0.43715851426124575)
('epoch', 503, 'train_loss:', 1.6667387294769287, 'val_loss:', 0.43450207352638243)
('epoch', 504, 'train_loss:', 1.6687558007240295, 'val_loss:', 0.43657037854194641)
('epoch', 505, 'train_loss:', 1.6664386296272278, 'val_loss:', 0.43611698865890502)
('epoch', 506, 'train_loss:', 1.665914216041565, 'val_loss:', 0.43592119216918945)
('epoch', 507, 'train_loss:', 1.663968403339386, 'val_loss:', 0.43400559306144715)
('epoch', 508, 'train_loss:', 1.6609472334384918, 'val_loss:', 0.43615755796432493)
('epoch', 509, 'train_loss:', 1.6649806785583496, 'val_loss:', 0.43429730415344237)
('epoch', 510, 'train_loss:', 1.6683883428573609, 'val_loss:', 0.4356159496307373)
('epoch', 511, 'train_loss:', 1.6611624228954316, 'val_loss:', 0.4345673060417175)
('epoch', 512, 'train_loss:', 1.6629844915866852, 'val_loss:', 0.43337124943733213)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 67965279 get requests, put_count=67965313 evicted_count=133000 eviction_rate=0.00195688 and unsatisfied allocation rate=0.0019571
('epoch', 513, 'train_loss:', 1.6618668949604034, 'val_loss:', 0.43507259488105776)
('epoch', 514, 'train_loss:', 1.6631971287727356, 'val_loss:', 0.43446686029434206)
('epoch', 515, 'train_loss:', 1.6606816661357879, 'val_loss:', 0.43353253245353701)
('epoch', 516, 'train_loss:', 1.6623955905437469, 'val_loss:', 0.4338731610774994)
('epoch', 517, 'train_loss:', 1.6598961937427521, 'val_loss:', 0.43430887579917909)
('epoch', 518, 'train_loss:', 1.659217050075531, 'val_loss:', 0.43441099166870117)
('epoch', 519, 'train_loss:', 1.6569967401027679, 'val_loss:', 0.4349997866153717)
('epoch', 520, 'train_loss:', 1.6598883497714996, 'val_loss:', 0.43337144374847414)
('epoch', 521, 'train_loss:', 1.6558487081527711, 'val_loss:', 0.43359290242195131)
('epoch', 522, 'train_loss:', 1.6585858166217804, 'val_loss:', 0.43361099243164064)
('epoch', 523, 'train_loss:', 1.6570221841335298, 'val_loss:', 0.43404590725898745)
('epoch', 524, 'train_loss:', 1.6565571486949922, 'val_loss:', 0.43344979763031005)
('epoch', 525, 'train_loss:', 1.6593395066261292, 'val_loss:', 0.43206551790237424)
('epoch', 526, 'train_loss:', 1.6546232533454894, 'val_loss:', 0.43361463546752932)
('epoch', 527, 'train_loss:', 1.6538513195514679, 'val_loss:', 0.4331548535823822)
('epoch', 528, 'train_loss:', 1.6571396696567535, 'val_loss:', 0.43266222953796385)
('epoch', 529, 'train_loss:', 1.6570873892307281, 'val_loss:', 0.43163104891777038)
('epoch', 530, 'train_loss:', 1.6554656267166137, 'val_loss:', 0.4344507944583893)
('epoch', 531, 'train_loss:', 1.6547168588638306, 'val_loss:', 0.4334206211566925)
('epoch', 532, 'train_loss:', 1.6520994293689728, 'val_loss:', 0.4349714946746826)
('epoch', 533, 'train_loss:', 1.6539862310886384, 'val_loss:', 0.43160284876823424)
('epoch', 534, 'train_loss:', 1.6502632284164429, 'val_loss:', 0.43405524730682371)
('epoch', 535, 'train_loss:', 1.651544327735901, 'val_loss:', 0.4324256765842438)
('epoch', 536, 'train_loss:', 1.6532606291770935, 'val_loss:', 0.43189749598503113)
('epoch', 537, 'train_loss:', 1.6530369293689728, 'val_loss:', 0.43406758546829222)
('epoch', 538, 'train_loss:', 1.6535538411140442, 'val_loss:', 0.43298282146453859)
('epoch', 539, 'train_loss:', 1.6538579297065734, 'val_loss:', 0.43148777961730955)
('epoch', 540, 'train_loss:', 1.6501377642154693, 'val_loss:', 0.43233187437057496)
('epoch', 541, 'train_loss:', 1.6522311353683472, 'val_loss:', 0.4325283920764923)
('epoch', 542, 'train_loss:', 1.6507217085361481, 'val_loss:', 0.43313228249549868)
('epoch', 543, 'train_loss:', 1.650682544708252, 'val_loss:', 0.43294118881225585)
('epoch', 544, 'train_loss:', 1.6495936691761017, 'val_loss:', 0.42996453642845156)
('epoch', 545, 'train_loss:', 1.6482791554927827, 'val_loss:', 0.43099873900413516)
('epoch', 546, 'train_loss:', 1.6440700137615203, 'val_loss:', 0.4314212906360626)
('epoch', 547, 'train_loss:', 1.6473761367797852, 'val_loss:', 0.43075857639312742)
('epoch', 548, 'train_loss:', 1.6472794246673583, 'val_loss:', 0.43285320878028871)
('epoch', 549, 'train_loss:', 1.6473043000698089, 'val_loss:', 0.43257156014442444)
('epoch', 550, 'train_loss:', 1.6480189752578736, 'val_loss:', 0.43312896251678468)
('epoch', 551, 'train_loss:', 1.6426686596870423, 'val_loss:', 0.43099480986595151)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 73103031 get requests, put_count=73103064 evicted_count=143000 eviction_rate=0.00195614 and unsatisfied allocation rate=0.00195636
('epoch', 552, 'train_loss:', 1.6456704866886138, 'val_loss:', 0.43181406736373901)
('epoch', 553, 'train_loss:', 1.6469314801692962, 'val_loss:', 0.43135549187660216)
('epoch', 554, 'train_loss:', 1.6472506868839263, 'val_loss:', 0.43302653074264524)
('epoch', 555, 'train_loss:', 1.6416167116165161, 'val_loss:', 0.429999794960022)
('epoch', 556, 'train_loss:', 1.6424377465248108, 'val_loss:', 0.43160515785217285)
('epoch', 557, 'train_loss:', 1.642167649269104, 'val_loss:', 0.43138091564178466)
('epoch', 558, 'train_loss:', 1.6409055685997009, 'val_loss:', 0.43091052055358886)
('epoch', 559, 'train_loss:', 1.6429296207427979, 'val_loss:', 0.43061516046524045)
('epoch', 560, 'train_loss:', 1.643033138513565, 'val_loss:', 0.42979916214942931)
('epoch', 561, 'train_loss:', 1.6395843625068665, 'val_loss:', 0.43251899957656859)
('epoch', 562, 'train_loss:', 1.638252136707306, 'val_loss:', 0.42964905142784121)
('epoch', 563, 'train_loss:', 1.6399712073802948, 'val_loss:', 0.43002707481384278)
('epoch', 564, 'train_loss:', 1.6369015991687774, 'val_loss:', 0.42972360968589784)
('epoch', 565, 'train_loss:', 1.6400280845165254, 'val_loss:', 0.43125368356704713)
('epoch', 566, 'train_loss:', 1.6382627809047698, 'val_loss:', 0.43131337165832517)
('epoch', 567, 'train_loss:', 1.6353329181671143, 'val_loss:', 0.43071527123451231)
('epoch', 568, 'train_loss:', 1.6359124958515168, 'val_loss:', 0.4290181636810303)
('epoch', 569, 'train_loss:', 1.6381496691703796, 'val_loss:', 0.43149402976036072)
('epoch', 570, 'train_loss:', 1.6368835628032685, 'val_loss:', 0.43124007821083071)
('epoch', 571, 'train_loss:', 1.6360738742351533, 'val_loss:', 0.42992491841316222)
('epoch', 572, 'train_loss:', 1.6371775627136231, 'val_loss:', 0.43081509590148925)
('epoch', 573, 'train_loss:', 1.6396296858787536, 'val_loss:', 0.43117511153221133)
('epoch', 574, 'train_loss:', 1.635300897359848, 'val_loss:', 0.43167217016220094)
('epoch', 575, 'train_loss:', 1.6340957701206207, 'val_loss:', 0.4303393626213074)
('epoch', 576, 'train_loss:', 1.6313638997077942, 'val_loss:', 0.42998884558677675)
('epoch', 577, 'train_loss:', 1.6337529659271239, 'val_loss:', 0.43042860984802245)
('epoch', 578, 'train_loss:', 1.6347239601612091, 'val_loss:', 0.43040131330490111)
('epoch', 579, 'train_loss:', 1.6352867913246154, 'val_loss:', 0.42768727898597719)
('epoch', 580, 'train_loss:', 1.6353440821170806, 'val_loss:', 0.42884858489036559)
('epoch', 581, 'train_loss:', 1.6307417452335358, 'val_loss:', 0.42982942938804625)
('epoch', 582, 'train_loss:', 1.6329228341579438, 'val_loss:', 0.4313799810409546)
('epoch', 583, 'train_loss:', 1.62928857088089, 'val_loss:', 0.42887450575828551)
('epoch', 584, 'train_loss:', 1.6311498689651489, 'val_loss:', 0.42959846615791319)
('epoch', 585, 'train_loss:', 1.6302691912651062, 'val_loss:', 0.43024170398712158)
('epoch', 586, 'train_loss:', 1.6277811551094055, 'val_loss:', 0.42829887747764589)
('epoch', 587, 'train_loss:', 1.6259231662750244, 'val_loss:', 0.42841851472854614)
('epoch', 588, 'train_loss:', 1.6315565013885498, 'val_loss:', 0.42951616406440735)
('epoch', 589, 'train_loss:', 1.6273255145549774, 'val_loss:', 0.42944633364677431)
('epoch', 590, 'train_loss:', 1.6272825455665589, 'val_loss:', 0.43145111918449403)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 78191238 get requests, put_count=78191271 evicted_count=153000 eviction_rate=0.00195674 and unsatisfied allocation rate=0.00195695
('epoch', 591, 'train_loss:', 1.6269126927852631, 'val_loss:', 0.43014615297317504)
('epoch', 592, 'train_loss:', 1.6252947425842286, 'val_loss:', 0.4294077730178833)
('epoch', 593, 'train_loss:', 1.6235100984573365, 'val_loss:', 0.42885948896408083)
('epoch', 594, 'train_loss:', 1.6289173531532288, 'val_loss:', 0.43059920430183413)
('epoch', 595, 'train_loss:', 1.6246925711631774, 'val_loss:', 0.42833668828010557)
('epoch', 596, 'train_loss:', 1.6213614463806152, 'val_loss:', 0.42754193782806399)
('epoch', 597, 'train_loss:', 1.626399120092392, 'val_loss:', 0.43113680720329284)
('epoch', 598, 'train_loss:', 1.6276738619804383, 'val_loss:', 0.42764176487922667)
('epoch', 599, 'train_loss:', 1.6248171126842499, 'val_loss:', 0.42824670433998108)
