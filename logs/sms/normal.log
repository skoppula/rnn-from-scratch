(keras)skoppula@sls-sm-7:~/lstm-testing/rnn-from-scratch$ CUDA_VISIBLE_DEVICES=0 python lstm_all_variants.py -t -d sms -v normal
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
{'dataset': 'sms', 'train': True, 'variant': 'normal', 'generate': False, 'num_words': None}
('fetched data. trn/test data shape: ', (9292, 30), (9292, 30), (2323, 30), (2323, 30))
('num steps in trn and val epochs', 36, 9)
('Model name', 'lstm_all_variants')
building graph...
created model.
starting to train model!
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:02:00.0
Total memory: 11.90GiB
Free memory: 11.76GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2280 get requests, put_count=2268 evicted_count=1000 eviction_rate=0.440917 and unsatisfied allocation rate=0.487719
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3416 get requests, put_count=3392 evicted_count=1000 eviction_rate=0.294811 and unsatisfied allocation rate=0.306499
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 256 to 281
('epoch', 0, 'train_loss:', 1.7646714735031128, 'val_loss:', 0.4321678018569946)
('epoch', 1, 'train_loss:', 1.7000838327407837, 'val_loss:', 0.417900972366333)
('epoch', 2, 'train_loss:', 1.6494863319396973, 'val_loss:', 0.40659168243408206)
('epoch', 3, 'train_loss:', 1.6046510076522826, 'val_loss:', 0.39528310775756836)
('epoch', 4, 'train_loss:', 1.5494827699661256, 'val_loss:', 0.37741712570190428)
('epoch', 5, 'train_loss:', 1.4803140783309936, 'val_loss:', 0.36166782140731812)
('epoch', 6, 'train_loss:', 1.4202912831306458, 'val_loss:', 0.34783125162124634)
('epoch', 7, 'train_loss:', 1.3715160489082336, 'val_loss:', 0.33823770761489869)
('epoch', 8, 'train_loss:', 1.3457702207565307, 'val_loss:', 0.33306130170822146)
('epoch', 9, 'train_loss:', 1.3249817395210266, 'val_loss:', 0.32900439500808715)
('epoch', 10, 'train_loss:', 1.3100198245048522, 'val_loss:', 0.32601107835769655)
('epoch', 11, 'train_loss:', 1.2954266142845154, 'val_loss:', 0.32132297277450561)
('epoch', 12, 'train_loss:', 1.2817031526565552, 'val_loss:', 0.31709306716918945)
('epoch', 13, 'train_loss:', 1.2645868253707886, 'val_loss:', 0.31268535375595091)
('epoch', 14, 'train_loss:', 1.2507936334609986, 'val_loss:', 0.31096938371658323)
('epoch', 15, 'train_loss:', 1.2379304647445679, 'val_loss:', 0.30512012004852296)
('epoch', 16, 'train_loss:', 1.2241342353820801, 'val_loss:', 0.30285587787628176)
('epoch', 17, 'train_loss:', 1.2058303189277648, 'val_loss:', 0.29852133035659789)
('epoch', 18, 'train_loss:', 1.191035451889038, 'val_loss:', 0.29540920734405518)
('epoch', 19, 'train_loss:', 1.1816118717193604, 'val_loss:', 0.29111953735351564)
('epoch', 20, 'train_loss:', 1.162706286907196, 'val_loss:', 0.28974022388458254)
('epoch', 21, 'train_loss:', 1.153671793937683, 'val_loss:', 0.28686338186264038)
('epoch', 22, 'train_loss:', 1.1366076040267945, 'val_loss:', 0.28450025081634522)
('epoch', 23, 'train_loss:', 1.1267683124542236, 'val_loss:', 0.2791544771194458)
('epoch', 24, 'train_loss:', 1.1192540693283082, 'val_loss:', 0.27485674619674683)
('epoch', 25, 'train_loss:', 1.0992482304573059, 'val_loss:', 0.27259087324142456)
('epoch', 26, 'train_loss:', 1.0908982157707214, 'val_loss:', 0.26861268520355225)
('epoch', 27, 'train_loss:', 1.0776785540580749, 'val_loss:', 0.26639025211334227)
('epoch', 28, 'train_loss:', 1.0654117035865784, 'val_loss:', 0.26354829788208006)
('epoch', 29, 'train_loss:', 1.0543846249580384, 'val_loss:', 0.27574494600296018)
('epoch', 30, 'train_loss:', 1.0397246360778809, 'val_loss:', 0.25696809053421021)
('epoch', 31, 'train_loss:', 1.0276260757446289, 'val_loss:', 0.25349208354949954)
('epoch', 32, 'train_loss:', 1.0148117136955261, 'val_loss:', 0.253777232170105)
('epoch', 33, 'train_loss:', 1.0072143244743348, 'val_loss:', 0.24728259563446045)
('epoch', 34, 'train_loss:', 0.99546218395233155, 'val_loss:', 0.24840082406997679)
('epoch', 35, 'train_loss:', 0.98925222158432002, 'val_loss:', 0.24679630279541015)
('epoch', 36, 'train_loss:', 0.97356721878051755, 'val_loss:', 0.24493053913116455)
('epoch', 37, 'train_loss:', 0.9715293169021606, 'val_loss:', 0.24257510423660278)
('epoch', 38, 'train_loss:', 0.96070665359497065, 'val_loss:', 0.23850296497344969)
('epoch', 39, 'train_loss:', 0.94840675354003912, 'val_loss:', 0.23663459062576295)
('epoch', 40, 'train_loss:', 0.94281618595123295, 'val_loss:', 0.23634793758392333)
('epoch', 41, 'train_loss:', 0.93227430105209352, 'val_loss:', 0.23345673084259033)
('epoch', 42, 'train_loss:', 0.92377610206603999, 'val_loss:', 0.23061178684234618)
('epoch', 43, 'train_loss:', 0.91489805698394777, 'val_loss:', 0.23134385824203491)
('epoch', 44, 'train_loss:', 0.90871628046035768, 'val_loss:', 0.22505326747894286)
('epoch', 45, 'train_loss:', 0.90253622531890865, 'val_loss:', 0.22611151695251464)
('epoch', 46, 'train_loss:', 0.89435954809188845, 'val_loss:', 0.22338712692260743)
('epoch', 47, 'train_loss:', 0.89346833229064937, 'val_loss:', 0.22593862533569337)
('epoch', 48, 'train_loss:', 0.88411295890808106, 'val_loss:', 0.22298466205596923)
('epoch', 49, 'train_loss:', 0.87533252954483032, 'val_loss:', 0.21872647047042848)
('epoch', 50, 'train_loss:', 0.86059316396713259, 'val_loss:', 0.2186945366859436)
('epoch', 51, 'train_loss:', 0.86722981929779053, 'val_loss:', 0.21476471900939942)
('epoch', 52, 'train_loss:', 0.85738745212554934, 'val_loss:', 0.21603274822235108)
('epoch', 53, 'train_loss:', 0.85187482357025146, 'val_loss:', 0.21336685895919799)
('epoch', 54, 'train_loss:', 0.84550546884536748, 'val_loss:', 0.21175169944763184)
('epoch', 55, 'train_loss:', 0.8408660888671875, 'val_loss:', 0.20828288078308105)
('epoch', 56, 'train_loss:', 0.8338819813728332, 'val_loss:', 0.20991087198257447)
('epoch', 57, 'train_loss:', 0.83301220655441288, 'val_loss:', 0.20679485321044921)
('epoch', 58, 'train_loss:', 0.82189992666244505, 'val_loss:', 0.20538259029388428)
('epoch', 59, 'train_loss:', 0.81830735206603999, 'val_loss:', 0.20751922845840454)
('epoch', 60, 'train_loss:', 0.81450337648391724, 'val_loss:', 0.2025368642807007)
('epoch', 61, 'train_loss:', 0.80699404716491696, 'val_loss:', 0.201866295337677)
('epoch', 62, 'train_loss:', 0.8057977056503296, 'val_loss:', 0.20253661155700683)
('epoch', 63, 'train_loss:', 0.79215179681777959, 'val_loss:', 0.19952426910400389)
('epoch', 64, 'train_loss:', 0.78934694766998292, 'val_loss:', 0.19620951414108276)
('epoch', 65, 'train_loss:', 0.79144857168197635, 'val_loss:', 0.19832777023315429)
('epoch', 66, 'train_loss:', 0.77863959074020384, 'val_loss:', 0.19745700120925902)
('epoch', 67, 'train_loss:', 0.77647783279418947, 'val_loss:', 0.19733109474182128)
('epoch', 68, 'train_loss:', 0.7727556991577148, 'val_loss:', 0.19602009773254395)
('epoch', 69, 'train_loss:', 0.7686427426338196, 'val_loss:', 0.19246868848800658)
('epoch', 70, 'train_loss:', 0.76181249618530278, 'val_loss:', 0.19048941612243653)
('epoch', 71, 'train_loss:', 0.75639426231384277, 'val_loss:', 0.19344781875610351)
('epoch', 72, 'train_loss:', 0.75272156953811642, 'val_loss:', 0.18902658939361572)
('epoch', 73, 'train_loss:', 0.75131494760513307, 'val_loss:', 0.18892592668533326)
('epoch', 74, 'train_loss:', 0.74114676356315612, 'val_loss:', 0.18781935453414916)
('epoch', 75, 'train_loss:', 0.73822337627410883, 'val_loss:', 0.18838346242904663)
('epoch', 76, 'train_loss:', 0.73435511469841008, 'val_loss:', 0.18863014459609986)
('epoch', 77, 'train_loss:', 0.73455291986465454, 'val_loss:', 0.18228741168975829)
('epoch', 78, 'train_loss:', 0.72893885731697083, 'val_loss:', 0.1849307870864868)
('epoch', 79, 'train_loss:', 0.72516895413398741, 'val_loss:', 0.18366707801818849)
('epoch', 80, 'train_loss:', 0.72172328591346746, 'val_loss:', 0.1835593068599701)
('epoch', 81, 'train_loss:', 0.71817581772804262, 'val_loss:', 0.18121691703796386)
('epoch', 82, 'train_loss:', 0.71147971987724301, 'val_loss:', 0.18398291230201722)
('epoch', 83, 'train_loss:', 0.70729714512825015, 'val_loss:', 0.18068671703338623)
('epoch', 84, 'train_loss:', 0.70290639042854308, 'val_loss:', 0.18012169003486633)
('epoch', 85, 'train_loss:', 0.70029967904090884, 'val_loss:', 0.17891331076622008)
('epoch', 86, 'train_loss:', 0.69793749690055851, 'val_loss:', 0.17566285371780396)
('epoch', 87, 'train_loss:', 0.69784790873527525, 'val_loss:', 0.17477446198463439)
('epoch', 88, 'train_loss:', 0.68813526988029483, 'val_loss:', 0.17782348155975342)
('epoch', 89, 'train_loss:', 0.68853484869003301, 'val_loss:', 0.17660499572753907)
('epoch', 90, 'train_loss:', 0.67880147218704223, 'val_loss:', 0.17578475832939147)
('epoch', 91, 'train_loss:', 0.68187085747718812, 'val_loss:', 0.17299491405487061)
('epoch', 92, 'train_loss:', 0.6781659054756165, 'val_loss:', 0.1745027208328247)
('epoch', 93, 'train_loss:', 0.66688446760177611, 'val_loss:', 0.17131330609321593)
('epoch', 94, 'train_loss:', 0.66950427770614629, 'val_loss:', 0.17085416674613951)
('epoch', 95, 'train_loss:', 0.66252921342849735, 'val_loss:', 0.17008913397789002)
('epoch', 96, 'train_loss:', 0.65934126734733578, 'val_loss:', 0.16963374853134155)
('epoch', 97, 'train_loss:', 0.65666959404945369, 'val_loss:', 0.16930696845054627)
('epoch', 98, 'train_loss:', 0.66200777292251589, 'val_loss:', 0.16703426122665405)
('epoch', 99, 'train_loss:', 0.65036994099617007, 'val_loss:', 0.16760331153869629)
('epoch', 100, 'train_loss:', 0.64844456553459162, 'val_loss:', 0.16811481237411499)
('epoch', 101, 'train_loss:', 0.64771303057670593, 'val_loss:', 0.16738490104675294)
('epoch', 102, 'train_loss:', 0.648343106508255, 'val_loss:', 0.16796727418899537)
('epoch', 103, 'train_loss:', 0.63866413593292237, 'val_loss:', 0.16549127459526061)
('epoch', 104, 'train_loss:', 0.63596184134483336, 'val_loss:', 0.16606478810310363)
('epoch', 105, 'train_loss:', 0.63595374941825866, 'val_loss:', 0.16423087239265441)
('epoch', 106, 'train_loss:', 0.62974335074424748, 'val_loss:', 0.16351554512977601)
('epoch', 107, 'train_loss:', 0.62980000257492064, 'val_loss:', 0.16385051846504212)
('epoch', 108, 'train_loss:', 0.62629040598869323, 'val_loss:', 0.16203091382980347)
('epoch', 109, 'train_loss:', 0.62301523685455318, 'val_loss:', 0.1621740710735321)
('epoch', 110, 'train_loss:', 0.61763464331626894, 'val_loss:', 0.16170656323432922)
('epoch', 111, 'train_loss:', 0.62324018836021422, 'val_loss:', 0.16024688482284546)
('epoch', 112, 'train_loss:', 0.61432281136512756, 'val_loss:', 0.16234488248825074)
('epoch', 113, 'train_loss:', 0.61249420881271366, 'val_loss:', 0.15726477146148682)
('epoch', 114, 'train_loss:', 0.61256860613822939, 'val_loss:', 0.15920648932456971)
('epoch', 115, 'train_loss:', 0.61201470136642455, 'val_loss:', 0.15508524298667908)
('epoch', 116, 'train_loss:', 0.60194363355636593, 'val_loss:', 0.15580886244773864)
('epoch', 117, 'train_loss:', 0.5997260689735413, 'val_loss:', 0.1600047206878662)
('epoch', 118, 'train_loss:', 0.59695066452026369, 'val_loss:', 0.15532572269439698)
('epoch', 119, 'train_loss:', 0.59684539437294004, 'val_loss:', 0.15677195906639099)
('epoch', 120, 'train_loss:', 0.590521274805069, 'val_loss:', 0.15368145942687989)
('epoch', 121, 'train_loss:', 0.59305242538452152, 'val_loss:', 0.15658370733261109)
('epoch', 122, 'train_loss:', 0.59079853177070618, 'val_loss:', 0.15459807038307191)
('epoch', 123, 'train_loss:', 0.58311622619628911, 'val_loss:', 0.1538354766368866)
('epoch', 124, 'train_loss:', 0.58466885685920711, 'val_loss:', 0.15278719544410704)
('epoch', 125, 'train_loss:', 0.58495252609252935, 'val_loss:', 0.1528263807296753)
('epoch', 126, 'train_loss:', 0.57751057028770447, 'val_loss:', 0.15356050491333006)
('epoch', 127, 'train_loss:', 0.57888464093208314, 'val_loss:', 0.14875359773635866)
('epoch', 128, 'train_loss:', 0.57363078355789188, 'val_loss:', 0.15131434440612793)
('epoch', 129, 'train_loss:', 0.57736472129821781, 'val_loss:', 0.15300706744194031)
('epoch', 130, 'train_loss:', 0.57088364958763127, 'val_loss:', 0.15072377443313598)
('epoch', 131, 'train_loss:', 0.56841043233871458, 'val_loss:', 0.14908447742462158)
('epoch', 132, 'train_loss:', 0.56566479325294494, 'val_loss:', 0.15060333728790284)
('epoch', 133, 'train_loss:', 0.5609269511699676, 'val_loss:', 0.14862118721008299)
('epoch', 134, 'train_loss:', 0.56126091837882996, 'val_loss:', 0.14755985379219055)
('epoch', 135, 'train_loss:', 0.56053321361541752, 'val_loss:', 0.14640439987182619)
('epoch', 136, 'train_loss:', 0.5596171975135803, 'val_loss:', 0.15061039447784424)
('epoch', 137, 'train_loss:', 0.55187904477119443, 'val_loss:', 0.14772668242454529)
('epoch', 138, 'train_loss:', 0.55651194095611567, 'val_loss:', 0.15070270419120788)
('epoch', 139, 'train_loss:', 0.54849995374679561, 'val_loss:', 0.14801891922950744)
('epoch', 140, 'train_loss:', 0.55028593897819522, 'val_loss:', 0.14852413892745972)
('epoch', 141, 'train_loss:', 0.54410469770431513, 'val_loss:', 0.14427194952964784)
('epoch', 142, 'train_loss:', 0.54684591174125674, 'val_loss:', 0.1463707447052002)
('epoch', 143, 'train_loss:', 0.541865485906601, 'val_loss:', 0.14646150469779967)
('epoch', 144, 'train_loss:', 0.5399764752388001, 'val_loss:', 0.14710182785987855)
('epoch', 145, 'train_loss:', 0.54206297159194949, 'val_loss:', 0.14501054644584654)
('epoch', 146, 'train_loss:', 0.53795518517494201, 'val_loss:', 0.14360589027404785)
('epoch', 147, 'train_loss:', 0.53700498700141908, 'val_loss:', 0.14435849070549012)
('epoch', 148, 'train_loss:', 0.5379544615745544, 'val_loss:', 0.14612630248069763)
('epoch', 149, 'train_loss:', 0.53087142586708069, 'val_loss:', 0.14405179500579834)
('epoch', 150, 'train_loss:', 0.52831565380096435, 'val_loss:', 0.14258161425590515)
('epoch', 151, 'train_loss:', 0.52978807449340826, 'val_loss:', 0.14340461492538453)
('epoch', 152, 'train_loss:', 0.52357832551002503, 'val_loss:', 0.14274136781692504)
('epoch', 153, 'train_loss:', 0.52649873375892642, 'val_loss:', 0.144434814453125)
('epoch', 154, 'train_loss:', 0.52430169105529789, 'val_loss:', 0.14031564593315124)
('epoch', 155, 'train_loss:', 0.52162129282951353, 'val_loss:', 0.14359604954719543)
('epoch', 156, 'train_loss:', 0.51899000406265261, 'val_loss:', 0.14568514466285706)
('epoch', 157, 'train_loss:', 0.51692991018295287, 'val_loss:', 0.14145177602767944)
('epoch', 158, 'train_loss:', 0.52076385140419001, 'val_loss:', 0.14253158688545228)
('epoch', 159, 'train_loss:', 0.51217839956283573, 'val_loss:', 0.1414715301990509)
('epoch', 160, 'train_loss:', 0.51009415626525878, 'val_loss:', 0.14520354986190795)
('epoch', 161, 'train_loss:', 0.51075505614280703, 'val_loss:', 0.14152394413948058)
('epoch', 162, 'train_loss:', 0.5102432537078857, 'val_loss:', 0.13955532908439636)
('epoch', 163, 'train_loss:', 0.50717738151550296, 'val_loss:', 0.14135637760162353)
('epoch', 164, 'train_loss:', 0.5079297292232513, 'val_loss:', 0.14217758774757386)
('epoch', 165, 'train_loss:', 0.50806745529174802, 'val_loss:', 0.13799659848213197)
('epoch', 166, 'train_loss:', 0.50347411990165714, 'val_loss:', 0.1417507779598236)
('epoch', 167, 'train_loss:', 0.49850268840789796, 'val_loss:', 0.13765171766281128)
('epoch', 168, 'train_loss:', 0.49656603693962098, 'val_loss:', 0.14148569345474243)
('epoch', 169, 'train_loss:', 0.50139518499374391, 'val_loss:', 0.13853547453880311)
('epoch', 170, 'train_loss:', 0.4924707520008087, 'val_loss:', 0.13698481559753417)
('epoch', 171, 'train_loss:', 0.49776592373847961, 'val_loss:', 0.13665876030921936)
('epoch', 172, 'train_loss:', 0.49432029128074645, 'val_loss:', 0.13777116060256958)
('epoch', 173, 'train_loss:', 0.49808463215827942, 'val_loss:', 0.13734522461891174)
('epoch', 174, 'train_loss:', 0.48824788689613341, 'val_loss:', 0.13804128766059875)
('epoch', 175, 'train_loss:', 0.48981292247772218, 'val_loss:', 0.13785863876342774)
('epoch', 176, 'train_loss:', 0.48821966409683226, 'val_loss:', 0.13530451536178589)
('epoch', 177, 'train_loss:', 0.4859894001483917, 'val_loss:', 0.13937870383262635)
('epoch', 178, 'train_loss:', 0.48457712888717652, 'val_loss:', 0.13912937641143799)
('epoch', 179, 'train_loss:', 0.48589428186416628, 'val_loss:', 0.13614524483680726)
('epoch', 180, 'train_loss:', 0.47777942180633542, 'val_loss:', 0.13882851004600524)
('epoch', 181, 'train_loss:', 0.47944479465484618, 'val_loss:', 0.136468106508255)
('epoch', 182, 'train_loss:', 0.47950024366378785, 'val_loss:', 0.13509986400604249)
('epoch', 183, 'train_loss:', 0.47569469928741454, 'val_loss:', 0.13586700201034546)
('epoch', 184, 'train_loss:', 0.47980671405792236, 'val_loss:', 0.13433042764663697)
('epoch', 185, 'train_loss:', 0.47409521579742431, 'val_loss:', 0.13656207919120789)
('epoch', 186, 'train_loss:', 0.47101889610290526, 'val_loss:', 0.13588026881217957)
('epoch', 187, 'train_loss:', 0.4686657440662384, 'val_loss:', 0.13690319299697876)
('epoch', 188, 'train_loss:', 0.46772104501724243, 'val_loss:', 0.13529052257537841)
('epoch', 189, 'train_loss:', 0.46699090600013732, 'val_loss:', 0.13518334388732911)
('epoch', 190, 'train_loss:', 0.4650499737262726, 'val_loss:', 0.13350255370140077)
('epoch', 191, 'train_loss:', 0.46220367074012758, 'val_loss:', 0.13840091109275818)
('epoch', 192, 'train_loss:', 0.46315989494323728, 'val_loss:', 0.13495151162147523)
('epoch', 193, 'train_loss:', 0.46119623541831972, 'val_loss:', 0.13663931965827941)
('epoch', 194, 'train_loss:', 0.4637618339061737, 'val_loss:', 0.13290083646774292)
('epoch', 195, 'train_loss:', 0.45518870115280152, 'val_loss:', 0.13433764100074769)
('epoch', 196, 'train_loss:', 0.45325667142868042, 'val_loss:', 0.13412923693656922)
('epoch', 197, 'train_loss:', 0.4603653287887573, 'val_loss:', 0.13535159349441528)
('epoch', 198, 'train_loss:', 0.45558192610740661, 'val_loss:', 0.13404432892799378)
('epoch', 199, 'train_loss:', 0.45503597140312196, 'val_loss:', 0.13570049285888672)
('epoch', 200, 'train_loss:', 0.4553788113594055, 'val_loss:', 0.13299334645271302)
('epoch', 201, 'train_loss:', 0.45190011262893676, 'val_loss:', 0.13383605718612671)
('epoch', 202, 'train_loss:', 0.45786943554878234, 'val_loss:', 0.13487568736076355)
('epoch', 203, 'train_loss:', 0.44647476434707639, 'val_loss:', 0.13255930304527283)
('epoch', 204, 'train_loss:', 0.44706003189086913, 'val_loss:', 0.13308557868003845)
('epoch', 205, 'train_loss:', 0.44913630962371826, 'val_loss:', 0.13291860699653626)
('epoch', 206, 'train_loss:', 0.44816990733146667, 'val_loss:', 0.13224032282829284)
('epoch', 207, 'train_loss:', 0.4469750761985779, 'val_loss:', 0.13226263165473939)
('epoch', 208, 'train_loss:', 0.44278548598289491, 'val_loss:', 0.13401867032051087)
('epoch', 209, 'train_loss:', 0.44109180092811584, 'val_loss:', 0.13306376338005066)
('epoch', 210, 'train_loss:', 0.44038147807121275, 'val_loss:', 0.13524065852165224)
('epoch', 211, 'train_loss:', 0.4419548487663269, 'val_loss:', 0.13390158414840697)
('epoch', 212, 'train_loss:', 0.43697855114936829, 'val_loss:', 0.13327191948890685)
('epoch', 213, 'train_loss:', 0.44255988240242006, 'val_loss:', 0.13060379147529602)
('epoch', 214, 'train_loss:', 0.43284157276153562, 'val_loss:', 0.13212476491928102)
('epoch', 215, 'train_loss:', 0.43653042197227476, 'val_loss:', 0.12992256045341491)
('epoch', 216, 'train_loss:', 0.43888105273246764, 'val_loss:', 0.13078413367271424)
('epoch', 217, 'train_loss:', 0.42832136392593384, 'val_loss:', 0.13351439952850341)
('epoch', 218, 'train_loss:', 0.43452501773834229, 'val_loss:', 0.13506749749183655)
('epoch', 219, 'train_loss:', 0.42924588322639468, 'val_loss:', 0.1309027099609375)
('epoch', 220, 'train_loss:', 0.43137527346611021, 'val_loss:', 0.1324748933315277)
('epoch', 221, 'train_loss:', 0.43526182651519774, 'val_loss:', 0.13137368321418763)
('epoch', 222, 'train_loss:', 0.43054439783096315, 'val_loss:', 0.13275718331336975)
('epoch', 223, 'train_loss:', 0.4286951768398285, 'val_loss:', 0.12979322433471679)
('epoch', 224, 'train_loss:', 0.42600989937782285, 'val_loss:', 0.13105612158775329)
('epoch', 225, 'train_loss:', 0.42184482574462889, 'val_loss:', 0.13198185443878174)
('epoch', 226, 'train_loss:', 0.42383764624595643, 'val_loss:', 0.13011177539825439)
('epoch', 227, 'train_loss:', 0.42511521100997923, 'val_loss:', 0.13166191220283507)
('epoch', 228, 'train_loss:', 0.41563305735588074, 'val_loss:', 0.13066368103027343)
('epoch', 229, 'train_loss:', 0.42133304715156555, 'val_loss:', 0.13075050950050354)
('epoch', 230, 'train_loss:', 0.4170094358921051, 'val_loss:', 0.13009773135185243)
('epoch', 231, 'train_loss:', 0.41602828025817873, 'val_loss:', 0.13131549596786499)
('epoch', 232, 'train_loss:', 0.41564999818801879, 'val_loss:', 0.13134057641029359)
('epoch', 233, 'train_loss:', 0.41883674263954163, 'val_loss:', 0.13024881243705749)
('epoch', 234, 'train_loss:', 0.41562618970870974, 'val_loss:', 0.13092879533767701)
('epoch', 235, 'train_loss:', 0.41477782368659971, 'val_loss:', 0.12863943696022034)
('epoch', 236, 'train_loss:', 0.41501930832862854, 'val_loss:', 0.13180911302566528)
('epoch', 237, 'train_loss:', 0.41215821027755739, 'val_loss:', 0.13227074265480041)
('epoch', 238, 'train_loss:', 0.40895688772201538, 'val_loss:', 0.12672675132751465)
('epoch', 239, 'train_loss:', 0.40961464762687683, 'val_loss:', 0.13124857306480409)
('epoch', 240, 'train_loss:', 0.40654960393905637, 'val_loss:', 0.12928363800048828)
('epoch', 241, 'train_loss:', 0.40883060097694396, 'val_loss:', 0.13101641535758973)
('epoch', 242, 'train_loss:', 0.40318804144859316, 'val_loss:', 0.12966762661933898)
('epoch', 243, 'train_loss:', 0.40207930088043214, 'val_loss:', 0.13034248471260071)
('epoch', 244, 'train_loss:', 0.40203833103179931, 'val_loss:', 0.12986305952072144)
('epoch', 245, 'train_loss:', 0.40236517310142517, 'val_loss:', 0.12896978020668029)
('epoch', 246, 'train_loss:', 0.39986289024353028, 'val_loss:', 0.12687719941139222)
('epoch', 247, 'train_loss:', 0.40001847147941588, 'val_loss:', 0.1311730945110321)
('epoch', 248, 'train_loss:', 0.40335785388946532, 'val_loss:', 0.12940585255622863)
('epoch', 249, 'train_loss:', 0.39598056316375735, 'val_loss:', 0.12857436180114745)
('epoch', 250, 'train_loss:', 0.39888940811157225, 'val_loss:', 0.12962356448173523)
('epoch', 251, 'train_loss:', 0.39902162373065947, 'val_loss:', 0.13135743379592896)
('epoch', 252, 'train_loss:', 0.39981255054473874, 'val_loss:', 0.12864814996719359)
('epoch', 253, 'train_loss:', 0.39591816902160643, 'val_loss:', 0.12786026835441588)
('epoch', 254, 'train_loss:', 0.38853287935256958, 'val_loss:', 0.12833800554275512)
('epoch', 255, 'train_loss:', 0.39084465265274049, 'val_loss:', 0.1281565821170807)
('epoch', 256, 'train_loss:', 0.39296110749244689, 'val_loss:', 0.1295103895664215)
('epoch', 257, 'train_loss:', 0.39351859331130984, 'val_loss:', 0.12711639642715455)
('epoch', 258, 'train_loss:', 0.38692873835563657, 'val_loss:', 0.12760148644447328)
('epoch', 259, 'train_loss:', 0.38679026722908022, 'val_loss:', 0.13037188410758971)
('epoch', 260, 'train_loss:', 0.38560795903205869, 'val_loss:', 0.13066867828369141)
('epoch', 261, 'train_loss:', 0.38514904856681825, 'val_loss:', 0.13102440237998964)
('epoch', 262, 'train_loss:', 0.38664243817329408, 'val_loss:', 0.12861680388450622)
('epoch', 263, 'train_loss:', 0.38495253562927245, 'val_loss:', 0.13016193270683288)
('epoch', 264, 'train_loss:', 0.3855541658401489, 'val_loss:', 0.13156760573387147)
('epoch', 265, 'train_loss:', 0.38739853620529174, 'val_loss:', 0.13097239375114442)
('epoch', 266, 'train_loss:', 0.38038788497447967, 'val_loss:', 0.12846545338630677)
('epoch', 267, 'train_loss:', 0.38031864166259766, 'val_loss:', 0.12852094888687135)
('epoch', 268, 'train_loss:', 0.37705575525760648, 'val_loss:', 0.13025185704231262)
('epoch', 269, 'train_loss:', 0.376766699552536, 'val_loss:', 0.13009204387664794)
('epoch', 270, 'train_loss:', 0.37329454541206358, 'val_loss:', 0.12769609451293945)
('epoch', 271, 'train_loss:', 0.37769573271274565, 'val_loss:', 0.12934850454330443)
('epoch', 272, 'train_loss:', 0.37380891442298891, 'val_loss:', 0.12952881097793578)
('epoch', 273, 'train_loss:', 0.38204813718795777, 'val_loss:', 0.13106518626213073)
('epoch', 274, 'train_loss:', 0.37482301592826844, 'val_loss:', 0.1307736837863922)
('epoch', 275, 'train_loss:', 0.36990119934082033, 'val_loss:', 0.13136825084686279)
('epoch', 276, 'train_loss:', 0.37246888995170591, 'val_loss:', 0.12930240511894225)
('epoch', 277, 'train_loss:', 0.37162159383296967, 'val_loss:', 0.12959507942199708)
('epoch', 278, 'train_loss:', 0.3721918660402298, 'val_loss:', 0.12998748064041138)
('epoch', 279, 'train_loss:', 0.37016080498695375, 'val_loss:', 0.12882662296295166)
('epoch', 280, 'train_loss:', 0.36548937380313873, 'val_loss:', 0.1323489499092102)
('epoch', 281, 'train_loss:', 0.36813151359558105, 'val_loss:', 0.12995320558547974)
('epoch', 282, 'train_loss:', 0.36734308660030363, 'val_loss:', 0.1292533266544342)
('epoch', 283, 'train_loss:', 0.36448271095752716, 'val_loss:', 0.12925068020820618)
('epoch', 284, 'train_loss:', 0.35724144756793974, 'val_loss:', 0.13159797310829163)
('epoch', 285, 'train_loss:', 0.35848031163215638, 'val_loss:', 0.13043783187866212)
('epoch', 286, 'train_loss:', 0.36731632947921755, 'val_loss:', 0.1299261498451233)
('epoch', 287, 'train_loss:', 0.36419376373291018, 'val_loss:', 0.13141841888427735)
('epoch', 288, 'train_loss:', 0.3604442846775055, 'val_loss:', 0.13221008181571961)
('epoch', 289, 'train_loss:', 0.35902110636234286, 'val_loss:', 0.12788954854011536)
('epoch', 290, 'train_loss:', 0.3561956763267517, 'val_loss:', 0.13019518971443175)
('epoch', 291, 'train_loss:', 0.36223392248153685, 'val_loss:', 0.12445091247558594)
('epoch', 292, 'train_loss:', 0.35808465659618377, 'val_loss:', 0.12890519499778746)
('epoch', 293, 'train_loss:', 0.35815478742122653, 'val_loss:', 0.13088640213012695)
('epoch', 294, 'train_loss:', 0.35800866425037386, 'val_loss:', 0.13252178072929383)
('epoch', 295, 'train_loss:', 0.35410228312015535, 'val_loss:', 0.13128673672676086)
('epoch', 296, 'train_loss:', 0.35367160081863402, 'val_loss:', 0.13214514017105103)
('epoch', 297, 'train_loss:', 0.35256474435329438, 'val_loss:', 0.12946597337722779)
('epoch', 298, 'train_loss:', 0.34738729476928709, 'val_loss:', 0.12830982685089112)
('epoch', 299, 'train_loss:', 0.35319635272026062, 'val_loss:', 0.12814864039421081)
('epoch', 300, 'train_loss:', 0.35034664273262023, 'val_loss:', 0.12847816824913025)
('epoch', 301, 'train_loss:', 0.34633681118488313, 'val_loss:', 0.13156453251838685)
('epoch', 302, 'train_loss:', 0.35403348386287692, 'val_loss:', 0.13028091549873352)
('epoch', 303, 'train_loss:', 0.35240275681018829, 'val_loss:', 0.13191115260124206)
('epoch', 304, 'train_loss:', 0.34928768277168276, 'val_loss:', 0.13059010982513428)
('epoch', 305, 'train_loss:', 0.34695225000381469, 'val_loss:', 0.13010742187499999)
('epoch', 306, 'train_loss:', 0.3478456336259842, 'val_loss:', 0.12768247365951538)
('epoch', 307, 'train_loss:', 0.35051253080368044, 'val_loss:', 0.13085346937179565)
('epoch', 308, 'train_loss:', 0.34265353381633756, 'val_loss:', 0.13265151739120484)
('epoch', 309, 'train_loss:', 0.34231361508369446, 'val_loss:', 0.12927559018135071)
('epoch', 310, 'train_loss:', 0.34145879805088042, 'val_loss:', 0.13423577070236206)
('epoch', 311, 'train_loss:', 0.3403065049648285, 'val_loss:', 0.12991956353187561)
('epoch', 312, 'train_loss:', 0.34112957954406736, 'val_loss:', 0.13269834637641906)
('epoch', 313, 'train_loss:', 0.34491317987442016, 'val_loss:', 0.13298322558403014)
('epoch', 314, 'train_loss:', 0.33730671942234042, 'val_loss:', 0.13202504754066469)
('epoch', 315, 'train_loss:', 0.33616863906383515, 'val_loss:', 0.12872408270835878)
('epoch', 316, 'train_loss:', 0.34052030026912689, 'val_loss:', 0.12783061742782592)
('epoch', 317, 'train_loss:', 0.33771158337593077, 'val_loss:', 0.1269244682788849)
('epoch', 318, 'train_loss:', 0.33448392868041993, 'val_loss:', 0.1275997531414032)
('epoch', 319, 'train_loss:', 0.3357231593132019, 'val_loss:', 0.13064804196357727)
('epoch', 320, 'train_loss:', 0.33480398952960966, 'val_loss:', 0.12973267555236817)
('epoch', 321, 'train_loss:', 0.33671416938304899, 'val_loss:', 0.13090310811996461)
('epoch', 322, 'train_loss:', 0.33498232960700991, 'val_loss:', 0.13184557557106019)
('epoch', 323, 'train_loss:', 0.32842948496341706, 'val_loss:', 0.12870583653450013)
('epoch', 324, 'train_loss:', 0.33422569334506991, 'val_loss:', 0.12950301766395569)
('epoch', 325, 'train_loss:', 0.32810348153114322, 'val_loss:', 0.13412789940834047)
('epoch', 326, 'train_loss:', 0.33052937507629393, 'val_loss:', 0.13016833782196044)
('epoch', 327, 'train_loss:', 0.32479813754558562, 'val_loss:', 0.13173841476440429)
('epoch', 328, 'train_loss:', 0.33261795341968536, 'val_loss:', 0.13232569217681886)
('epoch', 329, 'train_loss:', 0.32944056570529939, 'val_loss:', 0.130918310880661)
('epoch', 330, 'train_loss:', 0.32960302054882051, 'val_loss:', 0.13229335427284242)
('epoch', 331, 'train_loss:', 0.32396435797214507, 'val_loss:', 0.13391016721725463)
('epoch', 332, 'train_loss:', 0.32735366582870484, 'val_loss:', 0.13023108124732971)
('epoch', 333, 'train_loss:', 0.32837253868579863, 'val_loss:', 0.13030868172645568)
('epoch', 334, 'train_loss:', 0.32232608437538146, 'val_loss:', 0.12945136666297913)
('epoch', 335, 'train_loss:', 0.32156555831432343, 'val_loss:', 0.13032322406768798)
('epoch', 336, 'train_loss:', 0.32130009591579439, 'val_loss:', 0.13013854861259461)
('epoch', 337, 'train_loss:', 0.32084391236305237, 'val_loss:', 0.13267344355583191)
('epoch', 338, 'train_loss:', 0.32104640424251557, 'val_loss:', 0.13289053678512575)
('epoch', 339, 'train_loss:', 0.32157352030277253, 'val_loss:', 0.13203515052795411)
('epoch', 340, 'train_loss:', 0.31591837346553803, 'val_loss:', 0.13126767992973329)
('epoch', 341, 'train_loss:', 0.32038251399993894, 'val_loss:', 0.13094056367874146)
('epoch', 342, 'train_loss:', 0.32022258639335632, 'val_loss:', 0.12907196164131166)
('epoch', 343, 'train_loss:', 0.3168490958213806, 'val_loss:', 0.13203715324401855)
('epoch', 344, 'train_loss:', 0.31364869832992553, 'val_loss:', 0.13006510734558105)
('epoch', 345, 'train_loss:', 0.31607419729232789, 'val_loss:', 0.13257114768028258)
('epoch', 346, 'train_loss:', 0.31598710715770723, 'val_loss:', 0.13166251182556152)
('epoch', 347, 'train_loss:', 0.31512583136558531, 'val_loss:', 0.13060250043869018)
('epoch', 348, 'train_loss:', 0.3139024007320404, 'val_loss:', 0.1335284686088562)
('epoch', 349, 'train_loss:', 0.31170999228954316, 'val_loss:', 0.13230307936668395)
('epoch', 350, 'train_loss:', 0.3137986332178116, 'val_loss:', 0.13512809395790101)
('epoch', 351, 'train_loss:', 0.31308263242244722, 'val_loss:', 0.13002941966056825)
('epoch', 352, 'train_loss:', 0.30917534291744231, 'val_loss:', 0.13272575497627259)
('epoch', 353, 'train_loss:', 0.31040728986263277, 'val_loss:', 0.13313431143760682)
('epoch', 354, 'train_loss:', 0.30733016669750213, 'val_loss:', 0.12949119329452516)
('epoch', 355, 'train_loss:', 0.30628480434417726, 'val_loss:', 0.13318712353706361)
('epoch', 356, 'train_loss:', 0.30739271402359009, 'val_loss:', 0.13142165780067444)
('epoch', 357, 'train_loss:', 0.30998184621334074, 'val_loss:', 0.13427895426750183)
('epoch', 358, 'train_loss:', 0.30389394521713259, 'val_loss:', 0.13246434926986694)
('epoch', 359, 'train_loss:', 0.3068344122171402, 'val_loss:', 0.13078519344329834)
('epoch', 360, 'train_loss:', 0.30658714711666107, 'val_loss:', 0.13307564258575438)
('epoch', 361, 'train_loss:', 0.30212951004505156, 'val_loss:', 0.13048516511917113)
('epoch', 362, 'train_loss:', 0.3083891934156418, 'val_loss:', 0.13276947140693665)
('epoch', 363, 'train_loss:', 0.30176344573497771, 'val_loss:', 0.13455160260200499)
('epoch', 364, 'train_loss:', 0.30366974711418154, 'val_loss:', 0.1330141830444336)
('epoch', 365, 'train_loss:', 0.30262239694595339, 'val_loss:', 0.13397623896598815)
('epoch', 366, 'train_loss:', 0.30160900533199309, 'val_loss:', 0.12895658612251282)
('epoch', 367, 'train_loss:', 0.29967511653900147, 'val_loss:', 0.13565581798553467)
('epoch', 368, 'train_loss:', 0.29955073654651643, 'val_loss:', 0.13372259616851806)
('epoch', 369, 'train_loss:', 0.29876360893249509, 'val_loss:', 0.13138131380081178)
('epoch', 370, 'train_loss:', 0.30214473724365232, 'val_loss:', 0.13222668409347535)
('epoch', 371, 'train_loss:', 0.29625169038772581, 'val_loss:', 0.13114559412002563)
('epoch', 372, 'train_loss:', 0.29841405332088472, 'val_loss:', 0.12864502429962157)
('epoch', 373, 'train_loss:', 0.29602803289890289, 'val_loss:', 0.13119100213050841)
('epoch', 374, 'train_loss:', 0.30025532603263855, 'val_loss:', 0.13437125444412232)
('epoch', 375, 'train_loss:', 0.29711799263954164, 'val_loss:', 0.13227886080741882)
('epoch', 376, 'train_loss:', 0.29166422009468079, 'val_loss:', 0.13641539096832275)
('epoch', 377, 'train_loss:', 0.29253402650356292, 'val_loss:', 0.1334642255306244)
('epoch', 378, 'train_loss:', 0.29115430295467376, 'val_loss:', 0.13328067421913148)
('epoch', 379, 'train_loss:', 0.29205953061580658, 'val_loss:', 0.1329500424861908)
('epoch', 380, 'train_loss:', 0.2941005402803421, 'val_loss:', 0.13357754111289977)
('epoch', 381, 'train_loss:', 0.29071332216262818, 'val_loss:', 0.13616395711898804)
('epoch', 382, 'train_loss:', 0.29022694945335387, 'val_loss:', 0.13724273443222046)
('epoch', 383, 'train_loss:', 0.29388571321964263, 'val_loss:', 0.13563095331192015)
('epoch', 384, 'train_loss:', 0.28770341038703917, 'val_loss:', 0.13182490944862366)
('epoch', 385, 'train_loss:', 0.28895627379417421, 'val_loss:', 0.13262308359146119)
('epoch', 386, 'train_loss:', 0.28543710649013521, 'val_loss:', 0.13664605736732482)
('epoch', 387, 'train_loss:', 0.2868410950899124, 'val_loss:', 0.13683537244796753)
('epoch', 388, 'train_loss:', 0.28670461773872374, 'val_loss:', 0.13636406898498535)
('epoch', 389, 'train_loss:', 0.28706649124622347, 'val_loss:', 0.13495143771171569)
('epoch', 390, 'train_loss:', 0.28202970981597902, 'val_loss:', 0.13338360905647278)
('epoch', 391, 'train_loss:', 0.28759777903556821, 'val_loss:', 0.13489673018455506)
('epoch', 392, 'train_loss:', 0.28164161741733551, 'val_loss:', 0.13554792761802673)
('epoch', 393, 'train_loss:', 0.28367834150791166, 'val_loss:', 0.13437569618225098)
('epoch', 394, 'train_loss:', 0.28381524205207825, 'val_loss:', 0.13434877872467041)
('epoch', 395, 'train_loss:', 0.27985776543617247, 'val_loss:', 0.13424646019935607)
('epoch', 396, 'train_loss:', 0.27872431814670562, 'val_loss:', 0.13665723919868469)
('epoch', 397, 'train_loss:', 0.28063989758491514, 'val_loss:', 0.13544837832450868)
('epoch', 398, 'train_loss:', 0.28191487789154052, 'val_loss:', 0.13634851098060607)
('epoch', 399, 'train_loss:', 0.27893312513828278, 'val_loss:', 0.1360650360584259)
('epoch', 400, 'train_loss:', 0.28103012681007383, 'val_loss:', 0.13512159943580626)
('epoch', 401, 'train_loss:', 0.27625079572200772, 'val_loss:', 0.13261891961097716)
('epoch', 402, 'train_loss:', 0.2789902639389038, 'val_loss:', 0.13476178050041199)
('epoch', 403, 'train_loss:', 0.27856716096401213, 'val_loss:', 0.13473138093948364)
('epoch', 404, 'train_loss:', 0.27814536273479462, 'val_loss:', 0.13395918250083924)
('epoch', 405, 'train_loss:', 0.27835967957973479, 'val_loss:', 0.13482321619987489)
('epoch', 406, 'train_loss:', 0.27606974303722381, 'val_loss:', 0.13501777648925781)
('epoch', 407, 'train_loss:', 0.27180243849754332, 'val_loss:', 0.13691242218017577)
('epoch', 408, 'train_loss:', 0.27418367683887479, 'val_loss:', 0.13655895948410035)
('epoch', 409, 'train_loss:', 0.27386780500411989, 'val_loss:', 0.13439297318458557)
('epoch', 410, 'train_loss:', 0.27333069205284116, 'val_loss:', 0.14183290600776671)
('epoch', 411, 'train_loss:', 0.2717100143432617, 'val_loss:', 0.13724610924720765)
('epoch', 412, 'train_loss:', 0.2699344450235367, 'val_loss:', 0.1371770668029785)
('epoch', 413, 'train_loss:', 0.27351515948772431, 'val_loss:', 0.13500991344451904)
('epoch', 414, 'train_loss:', 0.27040917098522188, 'val_loss:', 0.13543033480644226)
('epoch', 415, 'train_loss:', 0.2680978924036026, 'val_loss:', 0.13777023434638977)
('epoch', 416, 'train_loss:', 0.2657663142681122, 'val_loss:', 0.13735051870346068)
('epoch', 417, 'train_loss:', 0.26711216449737551, 'val_loss:', 0.13763236999511719)
('epoch', 418, 'train_loss:', 0.26679560303688049, 'val_loss:', 0.1395734143257141)
('epoch', 419, 'train_loss:', 0.26973833978176115, 'val_loss:', 0.13752541661262513)
('epoch', 420, 'train_loss:', 0.26757120072841645, 'val_loss:', 0.14094311475753785)
('epoch', 421, 'train_loss:', 0.26772292494773864, 'val_loss:', 0.13624359965324401)
('epoch', 422, 'train_loss:', 0.26738144159317018, 'val_loss:', 0.13780517697334291)
('epoch', 423, 'train_loss:', 0.26706269502639768, 'val_loss:', 0.13498556852340698)
('epoch', 424, 'train_loss:', 0.26427515923976896, 'val_loss:', 0.13770304918289183)
('epoch', 425, 'train_loss:', 0.26719726502895358, 'val_loss:', 0.14035068035125733)
('epoch', 426, 'train_loss:', 0.2610030221939087, 'val_loss:', 0.14305577754974366)
('epoch', 427, 'train_loss:', 0.26214276552200316, 'val_loss:', 0.13915402293205262)
('epoch', 428, 'train_loss:', 0.26097926080226896, 'val_loss:', 0.13619006156921387)
('epoch', 429, 'train_loss:', 0.26472165942192077, 'val_loss:', 0.14098036050796509)
('epoch', 430, 'train_loss:', 0.26125322461128236, 'val_loss:', 0.14009281635284423)
('epoch', 431, 'train_loss:', 0.2603698366880417, 'val_loss:', 0.14159016966819762)
('epoch', 432, 'train_loss:', 0.26005913197994235, 'val_loss:', 0.13848827242851258)
('epoch', 433, 'train_loss:', 0.25758705437183382, 'val_loss:', 0.13771925449371339)
('epoch', 434, 'train_loss:', 0.25826989471912382, 'val_loss:', 0.14149888157844542)
('epoch', 435, 'train_loss:', 0.25899953722953795, 'val_loss:', 0.13715064287185669)
('epoch', 436, 'train_loss:', 0.26065424919128416, 'val_loss:', 0.1398432171344757)
('epoch', 437, 'train_loss:', 0.25622552752494809, 'val_loss:', 0.14115906715393067)
('epoch', 438, 'train_loss:', 0.26101512014865874, 'val_loss:', 0.13861492991447449)
('epoch', 439, 'train_loss:', 0.2563038796186447, 'val_loss:', 0.14131434798240661)
('epoch', 440, 'train_loss:', 0.25481233060359954, 'val_loss:', 0.13908479452133179)
('epoch', 441, 'train_loss:', 0.25564356029033664, 'val_loss:', 0.14094763398170471)
('epoch', 442, 'train_loss:', 0.25465592801570891, 'val_loss:', 0.13751721501350403)
('epoch', 443, 'train_loss:', 0.25186650991439818, 'val_loss:', 0.14060543656349181)
('epoch', 444, 'train_loss:', 0.2517003321647644, 'val_loss:', 0.14347950577735902)
('epoch', 445, 'train_loss:', 0.24939557194709777, 'val_loss:', 0.14020263791084289)
('epoch', 446, 'train_loss:', 0.25105663955211638, 'val_loss:', 0.13684133887290956)
('epoch', 447, 'train_loss:', 0.25442604780197142, 'val_loss:', 0.13903972983360291)
('epoch', 448, 'train_loss:', 0.24947427809238434, 'val_loss:', 0.13999736785888672)
('epoch', 449, 'train_loss:', 0.24936922252178192, 'val_loss:', 0.14123206853866577)
('epoch', 450, 'train_loss:', 0.25219186365604401, 'val_loss:', 0.14376091957092285)
('epoch', 451, 'train_loss:', 0.24789204239845275, 'val_loss:', 0.14362169027328492)
('epoch', 452, 'train_loss:', 0.24924522578716279, 'val_loss:', 0.13993144273757935)
('epoch', 453, 'train_loss:', 0.24791408717632293, 'val_loss:', 0.14181583881378174)
('epoch', 454, 'train_loss:', 0.24968330442905426, 'val_loss:', 0.14216418266296388)
('epoch', 455, 'train_loss:', 0.24818801224231721, 'val_loss:', 0.14103258609771729)
('epoch', 456, 'train_loss:', 0.24825563073158263, 'val_loss:', 0.14158012747764587)
('epoch', 457, 'train_loss:', 0.24596281588077545, 'val_loss:', 0.14476511001586914)
('epoch', 458, 'train_loss:', 0.24653697490692139, 'val_loss:', 0.14162354588508605)
('epoch', 459, 'train_loss:', 0.2433274668455124, 'val_loss:', 0.13837996363639832)
('epoch', 460, 'train_loss:', 0.24939580678939818, 'val_loss:', 0.14528871536254884)
('epoch', 461, 'train_loss:', 0.2486165052652359, 'val_loss:', 0.14117699027061462)
('epoch', 462, 'train_loss:', 0.24448885023593903, 'val_loss:', 0.14244876146316529)
('epoch', 463, 'train_loss:', 0.24691292285919189, 'val_loss:', 0.14483500480651856)
('epoch', 464, 'train_loss:', 0.24224977791309357, 'val_loss:', 0.14102588415145875)
('epoch', 465, 'train_loss:', 0.24274736940860747, 'val_loss:', 0.14251648068428038)
('epoch', 466, 'train_loss:', 0.23927410781383515, 'val_loss:', 0.14301837086677552)
('epoch', 467, 'train_loss:', 0.24167091608047486, 'val_loss:', 0.14141449213027954)
('epoch', 468, 'train_loss:', 0.24211965918540954, 'val_loss:', 0.13763193607330323)
('epoch', 469, 'train_loss:', 0.23745138525962831, 'val_loss:', 0.14048704981803894)
('epoch', 470, 'train_loss:', 0.24033249974250792, 'val_loss:', 0.14064484119415283)
('epoch', 471, 'train_loss:', 0.23756912827491761, 'val_loss:', 0.14462294340133666)
('epoch', 472, 'train_loss:', 0.23991064071655274, 'val_loss:', 0.13925679206848143)
('epoch', 473, 'train_loss:', 0.24070075869560242, 'val_loss:', 0.14256450772285462)
('epoch', 474, 'train_loss:', 0.23827423691749572, 'val_loss:', 0.14167528510093688)
('epoch', 475, 'train_loss:', 0.236696035861969, 'val_loss:', 0.13757897257804871)
('epoch', 476, 'train_loss:', 0.2370497053861618, 'val_loss:', 0.14156513214111327)
('epoch', 477, 'train_loss:', 0.23758667171001435, 'val_loss:', 0.14317686438560487)
('epoch', 478, 'train_loss:', 0.23471597254276275, 'val_loss:', 0.14683903574943544)
('epoch', 479, 'train_loss:', 0.24258658349514006, 'val_loss:', 0.14158803701400757)
('epoch', 480, 'train_loss:', 0.23419343709945678, 'val_loss:', 0.1424870240688324)
('epoch', 481, 'train_loss:', 0.23489401817321778, 'val_loss:', 0.1446510922908783)
('epoch', 482, 'train_loss:', 0.23266761302947997, 'val_loss:', 0.1454264485836029)
('epoch', 483, 'train_loss:', 0.23379162073135376, 'val_loss:', 0.14733111500740051)
('epoch', 484, 'train_loss:', 0.23214292228221894, 'val_loss:', 0.14431023240089416)
('epoch', 485, 'train_loss:', 0.2336236333847046, 'val_loss:', 0.14240457296371459)
('epoch', 486, 'train_loss:', 0.22796354234218597, 'val_loss:', 0.14414991617202758)
('epoch', 487, 'train_loss:', 0.22931919932365419, 'val_loss:', 0.14483632087707521)
('epoch', 488, 'train_loss:', 0.23181666135787965, 'val_loss:', 0.14362032532691957)
('epoch', 489, 'train_loss:', 0.23229476153850556, 'val_loss:', 0.14654351949691771)
('epoch', 490, 'train_loss:', 0.23037451982498169, 'val_loss:', 0.14357779026031495)
('epoch', 491, 'train_loss:', 0.23474698424339294, 'val_loss:', 0.14312528133392333)
('epoch', 492, 'train_loss:', 0.23047181189060212, 'val_loss:', 0.14236657738685607)
('epoch', 493, 'train_loss:', 0.22440856575965881, 'val_loss:', 0.14532396197319031)
('epoch', 494, 'train_loss:', 0.22632371544837951, 'val_loss:', 0.14747822880744935)
('epoch', 495, 'train_loss:', 0.23022955834865569, 'val_loss:', 0.14471636652946474)
('epoch', 496, 'train_loss:', 0.22800495386123656, 'val_loss:', 0.14524452447891234)
('epoch', 497, 'train_loss:', 0.22925379157066345, 'val_loss:', 0.14658927202224731)
('epoch', 498, 'train_loss:', 0.22363998532295226, 'val_loss:', 0.14562540769577026)
('epoch', 499, 'train_loss:', 0.2291860294342041, 'val_loss:', 0.14428858280181886)
('epoch', 500, 'train_loss:', 0.22402916729450226, 'val_loss:', 0.14529383659362793)
('epoch', 501, 'train_loss:', 0.22319540858268738, 'val_loss:', 0.1440703797340393)
('epoch', 502, 'train_loss:', 0.2240701711177826, 'val_loss:', 0.14554962515830994)
('epoch', 503, 'train_loss:', 0.22574981331825256, 'val_loss:', 0.14605345487594604)
('epoch', 504, 'train_loss:', 0.22330546677112578, 'val_loss:', 0.15055614829063416)
('epoch', 505, 'train_loss:', 0.2220208638906479, 'val_loss:', 0.14699830532073974)
('epoch', 506, 'train_loss:', 0.21865472078323364, 'val_loss:', 0.14950562715530397)
('epoch', 507, 'train_loss:', 0.2243778246641159, 'val_loss:', 0.14746001958847046)
('epoch', 508, 'train_loss:', 0.22819506347179414, 'val_loss:', 0.14617955923080445)
('epoch', 509, 'train_loss:', 0.21979754388332368, 'val_loss:', 0.14603066563606262)
('epoch', 510, 'train_loss:', 0.21928401827812194, 'val_loss:', 0.14777950167655945)
('epoch', 511, 'train_loss:', 0.22182579934597016, 'val_loss:', 0.14410825848579406)
('epoch', 512, 'train_loss:', 0.22101567745208739, 'val_loss:', 0.14399835228919983)
('epoch', 513, 'train_loss:', 0.22359525084495543, 'val_loss:', 0.14642239093780518)
('epoch', 514, 'train_loss:', 0.2197990083694458, 'val_loss:', 0.1457896661758423)
('epoch', 515, 'train_loss:', 0.21353517234325409, 'val_loss:', 0.14553255319595337)
('epoch', 516, 'train_loss:', 0.22024959981441497, 'val_loss:', 0.14573583126068115)
('epoch', 517, 'train_loss:', 0.21738462686538695, 'val_loss:', 0.14950899600982667)
('epoch', 518, 'train_loss:', 0.21641942918300627, 'val_loss:', 0.14444870710372926)
('epoch', 519, 'train_loss:', 0.21522542953491211, 'val_loss:', 0.14785939335823059)
('epoch', 520, 'train_loss:', 0.21681022882461548, 'val_loss:', 0.14856664896011351)
('epoch', 521, 'train_loss:', 0.21554452836513519, 'val_loss:', 0.14876273274421692)
('epoch', 522, 'train_loss:', 0.2286454063653946, 'val_loss:', 0.14710053205490112)
('epoch', 523, 'train_loss:', 0.2136834168434143, 'val_loss:', 0.1467637276649475)
('epoch', 524, 'train_loss:', 0.21207349181175231, 'val_loss:', 0.14834970355033875)
('epoch', 525, 'train_loss:', 0.21350713193416596, 'val_loss:', 0.14923808693885804)
('epoch', 526, 'train_loss:', 0.21801363706588744, 'val_loss:', 0.14347280621528624)
('epoch', 527, 'train_loss:', 0.21424636662006377, 'val_loss:', 0.148287615776062)
('epoch', 528, 'train_loss:', 0.21262225866317749, 'val_loss:', 0.1470499050617218)
('epoch', 529, 'train_loss:', 0.21499230265617369, 'val_loss:', 0.14622663855552673)
('epoch', 530, 'train_loss:', 0.20759103894233705, 'val_loss:', 0.14507928371429443)
('epoch', 531, 'train_loss:', 0.215332670211792, 'val_loss:', 0.14909378647804261)
('epoch', 532, 'train_loss:', 0.22031647980213165, 'val_loss:', 0.14870357155799865)
('epoch', 533, 'train_loss:', 0.21353375792503357, 'val_loss:', 0.15059415102005005)
('epoch', 534, 'train_loss:', 0.20844710469245911, 'val_loss:', 0.1495613181591034)
('epoch', 535, 'train_loss:', 0.20619229674339296, 'val_loss:', 0.14805665254592895)
('epoch', 536, 'train_loss:', 0.21736609816551208, 'val_loss:', 0.1511777913570404)
('epoch', 537, 'train_loss:', 0.20442725896835326, 'val_loss:', 0.15208575010299683)
('epoch', 538, 'train_loss:', 0.21524565517902375, 'val_loss:', 0.15320125937461854)
('epoch', 539, 'train_loss:', 0.20809804260730744, 'val_loss:', 0.14860477209091186)
('epoch', 540, 'train_loss:', 0.20556791484355927, 'val_loss:', 0.15238404750823975)
('epoch', 541, 'train_loss:', 0.21243110060691833, 'val_loss:', 0.14751529932022095)
('epoch', 542, 'train_loss:', 0.20573271393775941, 'val_loss:', 0.15006053328514099)
('epoch', 543, 'train_loss:', 0.20780433237552642, 'val_loss:', 0.14890034914016723)
('epoch', 544, 'train_loss:', 0.20957443416118621, 'val_loss:', 0.15260748863220214)
('epoch', 545, 'train_loss:', 0.20862093269824983, 'val_loss:', 0.15195100307464598)
('epoch', 546, 'train_loss:', 0.20190079927444457, 'val_loss:', 0.15054949402809142)
('epoch', 547, 'train_loss:', 0.20310317814350129, 'val_loss:', 0.14777445316314697)
('epoch', 548, 'train_loss:', 0.20457514584064485, 'val_loss:', 0.15214380621910095)
('epoch', 549, 'train_loss:', 0.21341555058956146, 'val_loss:', 0.15246036052703857)
('epoch', 550, 'train_loss:', 0.19807056427001954, 'val_loss:', 0.14705318093299866)
('epoch', 551, 'train_loss:', 0.20579018235206603, 'val_loss:', 0.14697867870330811)
('epoch', 552, 'train_loss:', 0.20182403981685637, 'val_loss:', 0.15168493509292602)
('epoch', 553, 'train_loss:', 0.20544403195381164, 'val_loss:', 0.15394066214561464)
('epoch', 554, 'train_loss:', 0.20281374096870422, 'val_loss:', 0.15148733615875243)
('epoch', 555, 'train_loss:', 0.20132220566272735, 'val_loss:', 0.15200433254241943)
('epoch', 556, 'train_loss:', 0.20463783740997316, 'val_loss:', 0.15071433186531066)
('epoch', 557, 'train_loss:', 0.20541661977767944, 'val_loss:', 0.15168528079986573)
('epoch', 558, 'train_loss:', 0.20300015389919282, 'val_loss:', 0.15214765787124634)
('epoch', 559, 'train_loss:', 0.20812982678413391, 'val_loss:', 0.1479142987728119)
('epoch', 560, 'train_loss:', 0.19786140143871309, 'val_loss:', 0.15228277206420898)
('epoch', 561, 'train_loss:', 0.20273824989795686, 'val_loss:', 0.15517292380332948)
('epoch', 562, 'train_loss:', 0.19835108399391174, 'val_loss:', 0.14802375078201294)
('epoch', 563, 'train_loss:', 0.19728842258453369, 'val_loss:', 0.15089673519134522)
('epoch', 564, 'train_loss:', 0.20113875985145568, 'val_loss:', 0.15136714696884154)
('epoch', 565, 'train_loss:', 0.1955389216542244, 'val_loss:', 0.14974726080894471)
('epoch', 566, 'train_loss:', 0.20365702986717224, 'val_loss:', 0.15527166604995726)
('epoch', 567, 'train_loss:', 0.20105170249938964, 'val_loss:', 0.15244571805000307)
('epoch', 568, 'train_loss:', 0.19480713844299316, 'val_loss:', 0.15501224279403686)
('epoch', 569, 'train_loss:', 0.1983012154698372, 'val_loss:', 0.15084234237670899)
('epoch', 570, 'train_loss:', 0.19705115228891373, 'val_loss:', 0.155633385181427)
('epoch', 571, 'train_loss:', 0.20534348070621491, 'val_loss:', 0.15204925179481507)
('epoch', 572, 'train_loss:', 0.19536772191524507, 'val_loss:', 0.15385155200958253)
('epoch', 573, 'train_loss:', 0.19576073408126832, 'val_loss:', 0.15288551688194274)
('epoch', 574, 'train_loss:', 0.19475325435400009, 'val_loss:', 0.15322964906692504)
('epoch', 575, 'train_loss:', 0.19250024378299713, 'val_loss:', 0.15458965778350831)
('epoch', 576, 'train_loss:', 0.19256715714931488, 'val_loss:', 0.15514487504959107)
('epoch', 577, 'train_loss:', 0.19760529518127443, 'val_loss:', 0.15273890852928163)
('epoch', 578, 'train_loss:', 0.19254748463630678, 'val_loss:', 0.15320667505264282)
('epoch', 579, 'train_loss:', 0.19963734567165375, 'val_loss:', 0.15554552435874938)
('epoch', 580, 'train_loss:', 0.19442435920238496, 'val_loss:', 0.15383441329002381)
('epoch', 581, 'train_loss:', 0.19698116481304168, 'val_loss:', 0.15206398487091063)
('epoch', 582, 'train_loss:', 0.19150044649839401, 'val_loss:', 0.15236581683158876)
('epoch', 583, 'train_loss:', 0.18715797781944274, 'val_loss:', 0.15190429568290711)
('epoch', 584, 'train_loss:', 0.19764902293682099, 'val_loss:', 0.15456987142562867)
('epoch', 585, 'train_loss:', 0.19363217771053315, 'val_loss:', 0.15556569695472716)
('epoch', 586, 'train_loss:', 0.19031858831644058, 'val_loss:', 0.15666503548622132)
('epoch', 587, 'train_loss:', 0.19300441145896913, 'val_loss:', 0.14996860623359681)
('epoch', 588, 'train_loss:', 0.18836580127477645, 'val_loss:', 0.15465098261833191)
('epoch', 589, 'train_loss:', 0.19227117031812668, 'val_loss:', 0.15479764938354493)
('epoch', 590, 'train_loss:', 0.18568835586309432, 'val_loss:', 0.15529752254486084)
('epoch', 591, 'train_loss:', 0.19117084681987762, 'val_loss:', 0.15625555157661439)
('epoch', 592, 'train_loss:', 0.19218669682741166, 'val_loss:', 0.15268891096115111)
('epoch', 593, 'train_loss:', 0.19120641708374023, 'val_loss:', 0.15518799185752868)
('epoch', 594, 'train_loss:', 0.19323327660560607, 'val_loss:', 0.15729193449020384)
('epoch', 595, 'train_loss:', 0.18387908160686492, 'val_loss:', 0.15823451280593873)
('epoch', 596, 'train_loss:', 0.18240578144788741, 'val_loss:', 0.1521569585800171)
('epoch', 597, 'train_loss:', 0.19866824984550477, 'val_loss:', 0.15737001299858094)
('epoch', 598, 'train_loss:', 0.19310988008975982, 'val_loss:', 0.15466814041137694)
('epoch', 599, 'train_loss:', 0.18571048080921174, 'val_loss:', 0.1560529327392578)
